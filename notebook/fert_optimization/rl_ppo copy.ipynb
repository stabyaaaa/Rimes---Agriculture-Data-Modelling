{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "a533c825",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import torch\n",
    "from torch import nn\n",
    "from torch.distributions import Normal\n",
    "from stable_baselines3 import PPO\n",
    "from stable_baselines3.common.vec_env import DummyVecEnv\n",
    "from gym import Env, spaces\n",
    "from sklearn.preprocessing import StandardScaler\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "e5c900ff",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv('../../dataset/final/merged_dataset_final_all_pp.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "2df67ed3",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.drop(columns='palika_num', inplace=True)\n",
    "df.drop(columns='district', inplace=True)\n",
    "df.drop(columns='province', inplace=True)\n",
    "df.drop(columns='palika', inplace=True)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "0132d405",
   "metadata": {},
   "outputs": [],
   "source": [
    "# # ---------------------------\n",
    "# # Load your data (replace with actual df)\n",
    "# # ---------------------------\n",
    "# # df = pd.read_csv('your_file.csv')\n",
    "# from sklearn.model_selection import train_test_split\n",
    "# # Drop problematic columns\n",
    "\n",
    "# # Define state (soil features) and action (fertilizers)\n",
    "# soil_cols = ['ph','organic_matter','total_nitrogen','potassium','p2o5','boron','zinc',\n",
    "#              'sand','clay','slit','parentsoil','crop','variety']\n",
    "# fert_cols = ['UREA1','UREA2','UREA3','DAP','MOP','organic','boron_fert']\n",
    "\n",
    "# # Fill missing values\n",
    "# for col in soil_cols:\n",
    "#     df[col].fillna(df[col].mean(), inplace=True)\n",
    "\n",
    "# for col in fert_cols:\n",
    "#     df[col].fillna(0, inplace=True)\n",
    "# X = df[soil_cols]\n",
    "# y = df[fert_cols]\n",
    "# # Take only 5000 samples\n",
    "# df_sample = df.sample(n=5000, random_state=42).reset_index(drop=True)\n",
    "# X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "# scaler = StandardScaler()\n",
    "# X_train[soil_cols] = scaler.fit_transform(X_train[soil_cols])  # fit on train only\n",
    "# X_test[soil_cols] = scaler.transform(X_test[soil_cols]) \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "87e6b753",
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Environment\n",
    "# # ---------------------------\n",
    "# class FertilizerEnv:\n",
    "#     def __init__(self, data):\n",
    "#         self.data = data.reset_index(drop=True)\n",
    "#         self.n_steps = len(data)\n",
    "#         self.n_features = data.shape[1]\n",
    "#         self.max_fertilizer = np.array([100, 100, 100, 50, 50, 5, 5], dtype=np.float32)\n",
    "#         self.current_idx = 0\n",
    "\n",
    "#     def reset(self):\n",
    "#         self.current_idx = 0\n",
    "#         return self.data.iloc[self.current_idx].values.astype(np.float32)\n",
    "\n",
    "#     def step(self, action):\n",
    "#         action = np.clip(action, 0, self.max_fertilizer)\n",
    "#         reward = -np.sum(np.square(action / self.max_fertilizer))  # closer to 0 is better\n",
    "#         self.current_idx += 1\n",
    "#         done = self.current_idx >= self.n_steps\n",
    "#         obs = self.data.iloc[self.current_idx % self.n_steps].values.astype(np.float32) if not done else np.zeros(self.n_features)\n",
    "#         return obs, reward, done, {}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "e3f7ab17",
   "metadata": {},
   "outputs": [],
   "source": [
    "# # PPO Agent\n",
    "# # ---------------------------\n",
    "# class PPOAgent:\n",
    "#     def __init__(self, input_dim, action_dim, lr=3e-4, gamma=0.99, clip=0.2, epochs=10):\n",
    "#         self.policy = PolicyNetwork(input_dim, action_dim)\n",
    "#         self.optimizer = torch.optim.Adam(self.policy.parameters(), lr=lr)\n",
    "#         self.gamma = gamma\n",
    "#         self.clip = clip\n",
    "#         self.epochs = epochs\n",
    "#         self.memory = []\n",
    "\n",
    "#     def select_action(self, state):\n",
    "#         state = torch.FloatTensor(state).unsqueeze(0)\n",
    "#         mu, std = self.policy(state)\n",
    "#         dist = Normal(mu, std)\n",
    "#         action = dist.sample()\n",
    "#         log_prob = dist.log_prob(action).sum(dim=1)\n",
    "#         return action.detach().numpy()[0], log_prob.detach()\n",
    "\n",
    "#     def store(self, state, action, log_prob, reward, done):\n",
    "#         self.memory.append((state, action, log_prob, reward, done))\n",
    "\n",
    "#     def compute_returns(self, rewards, dones):\n",
    "#         returns = []\n",
    "#         R = 0\n",
    "#         for r, done in zip(reversed(rewards), reversed(dones)):\n",
    "#             if done:\n",
    "#                 R = 0\n",
    "#             R = r + self.gamma * R\n",
    "#             returns.insert(0, R)\n",
    "#         return returns\n",
    "\n",
    "#     def train(self):\n",
    "#         if len(self.memory) == 0:\n",
    "#             return\n",
    "#         states, actions, old_log_probs, rewards, dones = zip(*self.memory)\n",
    "#         states = torch.FloatTensor(states)\n",
    "#         actions = torch.FloatTensor(actions)\n",
    "#         old_log_probs = torch.stack(old_log_probs)\n",
    "#         returns = torch.FloatTensor(self.compute_returns(rewards, dones))\n",
    "\n",
    "#         for _ in range(self.epochs):\n",
    "#             mu, std = self.policy(states)\n",
    "#             dist = Normal(mu, std)\n",
    "#             log_probs = dist.log_prob(actions).sum(dim=1)\n",
    "#             ratios = torch.exp(log_probs - old_log_probs)\n",
    "#             advantages = returns - returns.mean()\n",
    "#             surr1 = ratios * advantages\n",
    "#             surr2 = torch.clamp(ratios, 1 - self.clip, 1 + self.clip) * advantages\n",
    "#             loss = -torch.min(surr1, surr2).mean()\n",
    "#             self.optimizer.zero_grad()\n",
    "#             loss.backward()\n",
    "#             self.optimizer.step()\n",
    "#         self.memory = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "6c66a770",
   "metadata": {},
   "outputs": [],
   "source": [
    "# # PPO Network\n",
    "# # ---------------------------\n",
    "# class PolicyNetwork(nn.Module):\n",
    "#     def __init__(self, input_dim, action_dim):\n",
    "#         super().__init__()\n",
    "#         self.net = nn.Sequential(\n",
    "#             nn.Linear(input_dim, 128),\n",
    "#             nn.ReLU(),\n",
    "#             nn.Linear(128, 128),\n",
    "#             nn.ReLU()\n",
    "#         )\n",
    "#         self.mu = nn.Linear(128, action_dim)\n",
    "#         self.log_std = nn.Parameter(torch.zeros(action_dim))\n",
    "\n",
    "#     def forward(self, x):\n",
    "#         x = self.net(x)\n",
    "#         mu = self.mu(x)\n",
    "#         std = torch.exp(self.log_std)\n",
    "#         return mu, std"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "ebbd1223",
   "metadata": {},
   "outputs": [],
   "source": [
    "# # PPO Network\n",
    "# # ---------------------------\n",
    "# class PolicyNetwork(nn.Module):\n",
    "#     def __init__(self, input_dim, action_dim):\n",
    "#         super().__init__()\n",
    "#         self.net = nn.Sequential(\n",
    "#             nn.Linear(input_dim, 128),\n",
    "#             nn.ReLU(),\n",
    "#             nn.Linear(128, 128),\n",
    "#             nn.ReLU()\n",
    "#         )\n",
    "#         self.mu = nn.Linear(128, action_dim)\n",
    "#         self.log_std = nn.Parameter(torch.zeros(action_dim))\n",
    "\n",
    "#     def forward(self, x):\n",
    "#         x = self.net(x)\n",
    "#         mu = self.mu(x)\n",
    "#         std = torch.exp(self.log_std)\n",
    "#         return mu, std"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "b9ce37c2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# # PPO Agent\n",
    "# # ---------------------------\n",
    "# class PPOAgent:\n",
    "#     def __init__(self, input_dim, action_dim, lr=3e-4, gamma=0.99, clip=0.2, epochs=10):\n",
    "#         self.policy = PolicyNetwork(input_dim, action_dim)\n",
    "#         self.optimizer = torch.optim.Adam(self.policy.parameters(), lr=lr)\n",
    "#         self.gamma = gamma\n",
    "#         self.clip = clip\n",
    "#         self.epochs = epochs\n",
    "#         self.memory = []\n",
    "\n",
    "#     def select_action(self, state):\n",
    "#         state = torch.FloatTensor(state).unsqueeze(0)\n",
    "#         mu, std = self.policy(state)\n",
    "#         dist = Normal(mu, std)\n",
    "#         action = dist.sample()\n",
    "#         log_prob = dist.log_prob(action).sum(dim=1)\n",
    "#         return action.detach().numpy()[0], log_prob.detach()\n",
    "\n",
    "#     def store(self, state, action, log_prob, reward, done):\n",
    "#         self.memory.append((state, action, log_prob, reward, done))\n",
    "\n",
    "#     def compute_returns(self, rewards, dones):\n",
    "#         returns = []\n",
    "#         R = 0\n",
    "#         for r, done in zip(reversed(rewards), reversed(dones)):\n",
    "#             if done:\n",
    "#                 R = 0\n",
    "#             R = r + self.gamma * R\n",
    "#             returns.insert(0, R)\n",
    "#         return returns\n",
    "\n",
    "#     def train(self):\n",
    "#         if len(self.memory) == 0:\n",
    "#             return\n",
    "#         states, actions, old_log_probs, rewards, dones = zip(*self.memory)\n",
    "#         states = torch.FloatTensor(states)\n",
    "#         actions = torch.FloatTensor(actions)\n",
    "#         old_log_probs = torch.stack(old_log_probs)\n",
    "#         returns = torch.FloatTensor(self.compute_returns(rewards, dones))\n",
    "\n",
    "#         for _ in range(self.epochs):\n",
    "#             mu, std = self.policy(states)\n",
    "#             dist = Normal(mu, std)\n",
    "#             log_probs = dist.log_prob(actions).sum(dim=1)\n",
    "#             ratios = torch.exp(log_probs - old_log_probs)\n",
    "#             advantages = returns - returns.mean()\n",
    "#             surr1 = ratios * advantages\n",
    "#             surr2 = torch.clamp(ratios, 1 - self.clip, 1 + self.clip) * advantages\n",
    "#             loss = -torch.min(surr1, surr2).mean()\n",
    "#             self.optimizer.zero_grad()\n",
    "#             loss.backward()\n",
    "#             self.optimizer.step()\n",
    "#         self.memory = []\n",
    "\n",
    "# # ---------------------------\n",
    "# # Split features for environment\n",
    "# # ---------------------------\n",
    "# X = df_sample[soil_cols]\n",
    "# y = df_sample[fert_cols]  # not used in this reward setup\n",
    "\n",
    "# X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "# train_env_data = X_train.reset_index(drop=True)\n",
    "# test_env_data = X_test.reset_index(drop=True)\n",
    "\n",
    "# # ---------------------------\n",
    "# # Initialize PPO agent and environment\n",
    "# # ---------------------------\n",
    "# input_dim = X_train.shape[1]\n",
    "# action_dim = len(fert_cols)\n",
    "\n",
    "# env = FertilizerEnv(train_env_data)\n",
    "# agent = PPOAgent(input_dim=input_dim, action_dim=action_dim)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "b9028bb8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# # ---------------------------\n",
    "# # PPO Training Loop\n",
    "# # ---------------------------\n",
    "# n_episodes = 200\n",
    "# for ep in range(n_episodes):\n",
    "#     state = env.reset()\n",
    "#     done = False\n",
    "#     total_reward = 0\n",
    "\n",
    "#     while not done:\n",
    "#         action, log_prob = agent.select_action(state)\n",
    "#         next_state, reward, done, _ = env.step(action)\n",
    "#         agent.store(state, action, log_prob, reward, done)\n",
    "#         state = next_state\n",
    "#         total_reward += reward\n",
    "\n",
    "#     agent.train()\n",
    "#     print(f\"Episode {ep+1}/{n_episodes}, Total Reward: {total_reward:.4f}\")\n",
    "\n",
    "# # ---------------------------\n",
    "# # Test PPO agent\n",
    "# # ---------------------------\n",
    "# env_test = FertilizerEnv(test_env_data)\n",
    "# state = env_test.reset()\n",
    "# done = False\n",
    "# predictions = []\n",
    "\n",
    "# while not done:\n",
    "#     action, _ = agent.select_action(state)\n",
    "#     predictions.append(action)\n",
    "#     state, _, done, _ = env_test.step(action)\n",
    "\n",
    "# predictions = np.array(predictions)\n",
    "# print(\"Sample fertilizer predictions:\\n\", predictions[:5])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "b165fa83",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/20000, Train Loss: 1.027975, Val Loss: 0.950936\n",
      "Epoch 20/20000, Train Loss: 0.293016, Val Loss: 0.249730\n",
      "Epoch 40/20000, Train Loss: 0.102594, Val Loss: 0.058512\n",
      "Epoch 60/20000, Train Loss: 0.058829, Val Loss: 0.024618\n",
      "Epoch 80/20000, Train Loss: 0.043121, Val Loss: 0.013210\n",
      "Epoch 100/20000, Train Loss: 0.036401, Val Loss: 0.008193\n",
      "Epoch 120/20000, Train Loss: 0.030994, Val Loss: 0.005795\n",
      "Epoch 140/20000, Train Loss: 0.027537, Val Loss: 0.004255\n",
      "Epoch 160/20000, Train Loss: 0.024889, Val Loss: 0.003293\n",
      "Epoch 180/20000, Train Loss: 0.023085, Val Loss: 0.002555\n",
      "Epoch 200/20000, Train Loss: 0.021305, Val Loss: 0.002075\n",
      "Epoch 220/20000, Train Loss: 0.020349, Val Loss: 0.001692\n",
      "Epoch 240/20000, Train Loss: 0.019095, Val Loss: 0.001556\n",
      "Epoch 260/20000, Train Loss: 0.018073, Val Loss: 0.001360\n",
      "Epoch 280/20000, Train Loss: 0.017291, Val Loss: 0.001115\n",
      "Epoch 300/20000, Train Loss: 0.016940, Val Loss: 0.000968\n",
      "Epoch 320/20000, Train Loss: 0.016165, Val Loss: 0.001052\n",
      "Epoch 340/20000, Train Loss: 0.015723, Val Loss: 0.000968\n",
      "Epoch 360/20000, Train Loss: 0.015145, Val Loss: 0.000800\n",
      "Epoch 380/20000, Train Loss: 0.014943, Val Loss: 0.000745\n",
      "Epoch 400/20000, Train Loss: 0.014588, Val Loss: 0.000781\n",
      "Epoch 420/20000, Train Loss: 0.013880, Val Loss: 0.000696\n",
      "Epoch 440/20000, Train Loss: 0.013369, Val Loss: 0.000669\n",
      "Epoch 460/20000, Train Loss: 0.013250, Val Loss: 0.000628\n",
      "Epoch 480/20000, Train Loss: 0.013052, Val Loss: 0.000671\n",
      "Epoch 500/20000, Train Loss: 0.012438, Val Loss: 0.000691\n",
      "Epoch 520/20000, Train Loss: 0.012262, Val Loss: 0.000646\n",
      "Epoch 540/20000, Train Loss: 0.011914, Val Loss: 0.000562\n",
      "Epoch 560/20000, Train Loss: 0.012114, Val Loss: 0.000598\n",
      "Epoch 580/20000, Train Loss: 0.011695, Val Loss: 0.000646\n",
      "Epoch 600/20000, Train Loss: 0.011619, Val Loss: 0.000483\n",
      "Epoch 620/20000, Train Loss: 0.011518, Val Loss: 0.000620\n",
      "Epoch 640/20000, Train Loss: 0.011412, Val Loss: 0.000603\n",
      "Epoch 660/20000, Train Loss: 0.011050, Val Loss: 0.000596\n",
      "Epoch 680/20000, Train Loss: 0.010742, Val Loss: 0.000615\n",
      "Epoch 700/20000, Train Loss: 0.010734, Val Loss: 0.000610\n",
      "Epoch 720/20000, Train Loss: 0.010503, Val Loss: 0.000466\n",
      "Epoch 740/20000, Train Loss: 0.010531, Val Loss: 0.000546\n",
      "Epoch 760/20000, Train Loss: 0.010553, Val Loss: 0.000539\n",
      "Epoch 780/20000, Train Loss: 0.010233, Val Loss: 0.000522\n",
      "Epoch 800/20000, Train Loss: 0.009931, Val Loss: 0.000444\n",
      "Epoch 820/20000, Train Loss: 0.009792, Val Loss: 0.000612\n",
      "Epoch 840/20000, Train Loss: 0.009594, Val Loss: 0.000429\n",
      "Epoch 860/20000, Train Loss: 0.009688, Val Loss: 0.000475\n",
      "Epoch 880/20000, Train Loss: 0.009822, Val Loss: 0.000476\n",
      "Epoch 900/20000, Train Loss: 0.009496, Val Loss: 0.000482\n",
      "Epoch 920/20000, Train Loss: 0.009008, Val Loss: 0.000742\n",
      "Epoch 940/20000, Train Loss: 0.009219, Val Loss: 0.000432\n",
      "Epoch 960/20000, Train Loss: 0.009320, Val Loss: 0.000424\n",
      "Epoch 980/20000, Train Loss: 0.008962, Val Loss: 0.000627\n",
      "Epoch 1000/20000, Train Loss: 0.008859, Val Loss: 0.000445\n",
      "Epoch 1020/20000, Train Loss: 0.008853, Val Loss: 0.000507\n",
      "Epoch 1040/20000, Train Loss: 0.008719, Val Loss: 0.000507\n",
      "Epoch 1060/20000, Train Loss: 0.008730, Val Loss: 0.000434\n",
      "Epoch 1080/20000, Train Loss: 0.008758, Val Loss: 0.000396\n",
      "Epoch 1100/20000, Train Loss: 0.008472, Val Loss: 0.000509\n",
      "Epoch 1120/20000, Train Loss: 0.008315, Val Loss: 0.000399\n",
      "Epoch 1140/20000, Train Loss: 0.008320, Val Loss: 0.000428\n",
      "Epoch 1160/20000, Train Loss: 0.008370, Val Loss: 0.000410\n",
      "Epoch 1180/20000, Train Loss: 0.008136, Val Loss: 0.000450\n",
      "Epoch 1200/20000, Train Loss: 0.008031, Val Loss: 0.000477\n",
      "Epoch 1220/20000, Train Loss: 0.008031, Val Loss: 0.000653\n",
      "Epoch 1240/20000, Train Loss: 0.007975, Val Loss: 0.000688\n",
      "Epoch 1260/20000, Train Loss: 0.007798, Val Loss: 0.000635\n",
      "Epoch 1280/20000, Train Loss: 0.008007, Val Loss: 0.000633\n",
      "Epoch 1300/20000, Train Loss: 0.007895, Val Loss: 0.000593\n",
      "Epoch 1320/20000, Train Loss: 0.007777, Val Loss: 0.000378\n",
      "Epoch 1340/20000, Train Loss: 0.007731, Val Loss: 0.000466\n",
      "Epoch 1360/20000, Train Loss: 0.007639, Val Loss: 0.000372\n",
      "Epoch 1380/20000, Train Loss: 0.007748, Val Loss: 0.000441\n",
      "Epoch 1400/20000, Train Loss: 0.007475, Val Loss: 0.000482\n",
      "Epoch 1420/20000, Train Loss: 0.007432, Val Loss: 0.000515\n",
      "Epoch 1440/20000, Train Loss: 0.007294, Val Loss: 0.000298\n",
      "Epoch 1460/20000, Train Loss: 0.007346, Val Loss: 0.000510\n",
      "Epoch 1480/20000, Train Loss: 0.007196, Val Loss: 0.000359\n",
      "Epoch 1500/20000, Train Loss: 0.007205, Val Loss: 0.000283\n",
      "Epoch 1520/20000, Train Loss: 0.007214, Val Loss: 0.000334\n",
      "Epoch 1540/20000, Train Loss: 0.007114, Val Loss: 0.000757\n",
      "Epoch 1560/20000, Train Loss: 0.007197, Val Loss: 0.000296\n",
      "Epoch 1580/20000, Train Loss: 0.006848, Val Loss: 0.000475\n",
      "Epoch 1600/20000, Train Loss: 0.006932, Val Loss: 0.000289\n",
      "Epoch 1620/20000, Train Loss: 0.006868, Val Loss: 0.000472\n",
      "Epoch 1640/20000, Train Loss: 0.006858, Val Loss: 0.000364\n",
      "Epoch 1660/20000, Train Loss: 0.006932, Val Loss: 0.000300\n",
      "Epoch 1680/20000, Train Loss: 0.006785, Val Loss: 0.000305\n",
      "Epoch 1700/20000, Train Loss: 0.006653, Val Loss: 0.000407\n",
      "Epoch 1720/20000, Train Loss: 0.006748, Val Loss: 0.000242\n",
      "Epoch 1740/20000, Train Loss: 0.006561, Val Loss: 0.000592\n",
      "Epoch 1760/20000, Train Loss: 0.006611, Val Loss: 0.000186\n",
      "Epoch 1780/20000, Train Loss: 0.006639, Val Loss: 0.000307\n",
      "Epoch 1800/20000, Train Loss: 0.006635, Val Loss: 0.000224\n",
      "Epoch 1820/20000, Train Loss: 0.006427, Val Loss: 0.000290\n",
      "Epoch 1840/20000, Train Loss: 0.006180, Val Loss: 0.000327\n",
      "Epoch 1860/20000, Train Loss: 0.006374, Val Loss: 0.000327\n",
      "Epoch 1880/20000, Train Loss: 0.006245, Val Loss: 0.000262\n",
      "Epoch 1900/20000, Train Loss: 0.006176, Val Loss: 0.000285\n",
      "Epoch 1920/20000, Train Loss: 0.006112, Val Loss: 0.000276\n",
      "Epoch 1940/20000, Train Loss: 0.006096, Val Loss: 0.000135\n",
      "Epoch 1960/20000, Train Loss: 0.006313, Val Loss: 0.000333\n",
      "Epoch 1980/20000, Train Loss: 0.006288, Val Loss: 0.000316\n",
      "Epoch 2000/20000, Train Loss: 0.006056, Val Loss: 0.000162\n",
      "Epoch 2020/20000, Train Loss: 0.006197, Val Loss: 0.000173\n",
      "Epoch 2040/20000, Train Loss: 0.006231, Val Loss: 0.000162\n",
      "Epoch 2060/20000, Train Loss: 0.006108, Val Loss: 0.000140\n",
      "Epoch 2080/20000, Train Loss: 0.006088, Val Loss: 0.000169\n",
      "Epoch 2100/20000, Train Loss: 0.006044, Val Loss: 0.000145\n",
      "Epoch 2120/20000, Train Loss: 0.005960, Val Loss: 0.000127\n",
      "Epoch 2140/20000, Train Loss: 0.005980, Val Loss: 0.000423\n",
      "Epoch 2160/20000, Train Loss: 0.006015, Val Loss: 0.000198\n",
      "Epoch 2180/20000, Train Loss: 0.005981, Val Loss: 0.000179\n",
      "Epoch 2200/20000, Train Loss: 0.006085, Val Loss: 0.000260\n",
      "Epoch 2220/20000, Train Loss: 0.005984, Val Loss: 0.000171\n",
      "Epoch 2240/20000, Train Loss: 0.005870, Val Loss: 0.000233\n",
      "Epoch 2260/20000, Train Loss: 0.006041, Val Loss: 0.000303\n",
      "Epoch 2280/20000, Train Loss: 0.006067, Val Loss: 0.000101\n",
      "Epoch 2300/20000, Train Loss: 0.005862, Val Loss: 0.000092\n",
      "Epoch 2320/20000, Train Loss: 0.006010, Val Loss: 0.000257\n",
      "Epoch 2340/20000, Train Loss: 0.005711, Val Loss: 0.000199\n",
      "Epoch 2360/20000, Train Loss: 0.005663, Val Loss: 0.000157\n",
      "Epoch 2380/20000, Train Loss: 0.005725, Val Loss: 0.000102\n",
      "Epoch 2400/20000, Train Loss: 0.005749, Val Loss: 0.000127\n",
      "Epoch 2420/20000, Train Loss: 0.005589, Val Loss: 0.000102\n",
      "Epoch 2440/20000, Train Loss: 0.005801, Val Loss: 0.000130\n",
      "Epoch 2460/20000, Train Loss: 0.005692, Val Loss: 0.000139\n",
      "Epoch 2480/20000, Train Loss: 0.005795, Val Loss: 0.000100\n",
      "Epoch 2500/20000, Train Loss: 0.005624, Val Loss: 0.000128\n",
      "Epoch 2520/20000, Train Loss: 0.005650, Val Loss: 0.000083\n",
      "Epoch 2540/20000, Train Loss: 0.005751, Val Loss: 0.000129\n",
      "Epoch 2560/20000, Train Loss: 0.005554, Val Loss: 0.000161\n",
      "Epoch 2580/20000, Train Loss: 0.005708, Val Loss: 0.000098\n",
      "Epoch 2600/20000, Train Loss: 0.005657, Val Loss: 0.000169\n",
      "Epoch 2620/20000, Train Loss: 0.005754, Val Loss: 0.000164\n",
      "Epoch 2640/20000, Train Loss: 0.005600, Val Loss: 0.000089\n",
      "Epoch 2660/20000, Train Loss: 0.005459, Val Loss: 0.000129\n",
      "Epoch 2680/20000, Train Loss: 0.005455, Val Loss: 0.000200\n",
      "Epoch 2700/20000, Train Loss: 0.005699, Val Loss: 0.000130\n",
      "Epoch 2720/20000, Train Loss: 0.005632, Val Loss: 0.000127\n",
      "Epoch 2740/20000, Train Loss: 0.005420, Val Loss: 0.000080\n",
      "Epoch 2760/20000, Train Loss: 0.005556, Val Loss: 0.000192\n",
      "Epoch 2780/20000, Train Loss: 0.005616, Val Loss: 0.000146\n",
      "Epoch 2800/20000, Train Loss: 0.005691, Val Loss: 0.000082\n",
      "Epoch 2820/20000, Train Loss: 0.005478, Val Loss: 0.000149\n",
      "Epoch 2840/20000, Train Loss: 0.005627, Val Loss: 0.000190\n",
      "Epoch 2860/20000, Train Loss: 0.005439, Val Loss: 0.000165\n",
      "Epoch 2880/20000, Train Loss: 0.005516, Val Loss: 0.000082\n",
      "Epoch 2900/20000, Train Loss: 0.005515, Val Loss: 0.000185\n",
      "Epoch 2920/20000, Train Loss: 0.005407, Val Loss: 0.000193\n",
      "Epoch 2940/20000, Train Loss: 0.005318, Val Loss: 0.000104\n",
      "Epoch 2960/20000, Train Loss: 0.005302, Val Loss: 0.000227\n",
      "Epoch 2980/20000, Train Loss: 0.005475, Val Loss: 0.000083\n",
      "Epoch 3000/20000, Train Loss: 0.005427, Val Loss: 0.000109\n",
      "Epoch 3020/20000, Train Loss: 0.005356, Val Loss: 0.000115\n",
      "Epoch 3040/20000, Train Loss: 0.005488, Val Loss: 0.000100\n",
      "Epoch 3060/20000, Train Loss: 0.005331, Val Loss: 0.000118\n",
      "Epoch 3080/20000, Train Loss: 0.005421, Val Loss: 0.000108\n",
      "Epoch 3100/20000, Train Loss: 0.005377, Val Loss: 0.000099\n",
      "Epoch 3120/20000, Train Loss: 0.005298, Val Loss: 0.000184\n",
      "Epoch 3140/20000, Train Loss: 0.005455, Val Loss: 0.000168\n",
      "Epoch 3160/20000, Train Loss: 0.005331, Val Loss: 0.000165\n",
      "Epoch 3180/20000, Train Loss: 0.005418, Val Loss: 0.000126\n",
      "Epoch 3200/20000, Train Loss: 0.005259, Val Loss: 0.000077\n",
      "Epoch 3220/20000, Train Loss: 0.005439, Val Loss: 0.000111\n",
      "Epoch 3240/20000, Train Loss: 0.005367, Val Loss: 0.000131\n",
      "Epoch 3260/20000, Train Loss: 0.005452, Val Loss: 0.000127\n",
      "Epoch 3280/20000, Train Loss: 0.005258, Val Loss: 0.000154\n",
      "Epoch 3300/20000, Train Loss: 0.005383, Val Loss: 0.000092\n",
      "Epoch 3320/20000, Train Loss: 0.005292, Val Loss: 0.000067\n",
      "Epoch 3340/20000, Train Loss: 0.005297, Val Loss: 0.000183\n",
      "Epoch 3360/20000, Train Loss: 0.005436, Val Loss: 0.000110\n",
      "Epoch 3380/20000, Train Loss: 0.005287, Val Loss: 0.000080\n",
      "Epoch 3400/20000, Train Loss: 0.005256, Val Loss: 0.000065\n",
      "Epoch 3420/20000, Train Loss: 0.005321, Val Loss: 0.000058\n",
      "Epoch 3440/20000, Train Loss: 0.005248, Val Loss: 0.000183\n",
      "Epoch 3460/20000, Train Loss: 0.005159, Val Loss: 0.000114\n",
      "Epoch 3480/20000, Train Loss: 0.005234, Val Loss: 0.000083\n",
      "Epoch 3500/20000, Train Loss: 0.005306, Val Loss: 0.000156\n",
      "Epoch 3520/20000, Train Loss: 0.005415, Val Loss: 0.000267\n",
      "Epoch 3540/20000, Train Loss: 0.005281, Val Loss: 0.000081\n",
      "Epoch 3560/20000, Train Loss: 0.005179, Val Loss: 0.000090\n",
      "Epoch 3580/20000, Train Loss: 0.005180, Val Loss: 0.000089\n",
      "Epoch 3600/20000, Train Loss: 0.005262, Val Loss: 0.000106\n",
      "Epoch 3620/20000, Train Loss: 0.005142, Val Loss: 0.000124\n",
      "Epoch 3640/20000, Train Loss: 0.005235, Val Loss: 0.000175\n",
      "Epoch 3660/20000, Train Loss: 0.005207, Val Loss: 0.000092\n",
      "Epoch 3680/20000, Train Loss: 0.005154, Val Loss: 0.000189\n",
      "Epoch 3700/20000, Train Loss: 0.005234, Val Loss: 0.000098\n",
      "Epoch 3720/20000, Train Loss: 0.005180, Val Loss: 0.000216\n",
      "Epoch 3740/20000, Train Loss: 0.005115, Val Loss: 0.000127\n",
      "Epoch 3760/20000, Train Loss: 0.005244, Val Loss: 0.000063\n",
      "Epoch 3780/20000, Train Loss: 0.005127, Val Loss: 0.000099\n",
      "Epoch 3800/20000, Train Loss: 0.005234, Val Loss: 0.000090\n",
      "Epoch 3820/20000, Train Loss: 0.005261, Val Loss: 0.000128\n",
      "Epoch 3840/20000, Train Loss: 0.005161, Val Loss: 0.000054\n",
      "Epoch 3860/20000, Train Loss: 0.005199, Val Loss: 0.000069\n",
      "Epoch 3880/20000, Train Loss: 0.005171, Val Loss: 0.000146\n",
      "Epoch 3900/20000, Train Loss: 0.005174, Val Loss: 0.000072\n",
      "Epoch 3920/20000, Train Loss: 0.005142, Val Loss: 0.000133\n",
      "Epoch 3940/20000, Train Loss: 0.005205, Val Loss: 0.000093\n",
      "Epoch 3960/20000, Train Loss: 0.005121, Val Loss: 0.000083\n",
      "Epoch 3980/20000, Train Loss: 0.005163, Val Loss: 0.000055\n",
      "Epoch 4000/20000, Train Loss: 0.005120, Val Loss: 0.000124\n",
      "Epoch 4020/20000, Train Loss: 0.005142, Val Loss: 0.000124\n",
      "Epoch 4040/20000, Train Loss: 0.005218, Val Loss: 0.000050\n",
      "Epoch 4060/20000, Train Loss: 0.005214, Val Loss: 0.000062\n",
      "Epoch 4080/20000, Train Loss: 0.005263, Val Loss: 0.000140\n",
      "Epoch 4100/20000, Train Loss: 0.005098, Val Loss: 0.000155\n",
      "Epoch 4120/20000, Train Loss: 0.005089, Val Loss: 0.000091\n",
      "Epoch 4140/20000, Train Loss: 0.005215, Val Loss: 0.000129\n",
      "Epoch 4160/20000, Train Loss: 0.005084, Val Loss: 0.000126\n",
      "Epoch 4180/20000, Train Loss: 0.005239, Val Loss: 0.000162\n",
      "Epoch 4200/20000, Train Loss: 0.005081, Val Loss: 0.000085\n",
      "Epoch 4220/20000, Train Loss: 0.005153, Val Loss: 0.000122\n",
      "Epoch 4240/20000, Train Loss: 0.005268, Val Loss: 0.000195\n",
      "Epoch 4260/20000, Train Loss: 0.004963, Val Loss: 0.000048\n",
      "Epoch 4280/20000, Train Loss: 0.005034, Val Loss: 0.000142\n",
      "Epoch 4300/20000, Train Loss: 0.005053, Val Loss: 0.000080\n",
      "Epoch 4320/20000, Train Loss: 0.005128, Val Loss: 0.000093\n",
      "Epoch 4340/20000, Train Loss: 0.005168, Val Loss: 0.000185\n",
      "Epoch 4360/20000, Train Loss: 0.005255, Val Loss: 0.000128\n",
      "Epoch 4380/20000, Train Loss: 0.004996, Val Loss: 0.000054\n",
      "Epoch 4400/20000, Train Loss: 0.005140, Val Loss: 0.000146\n",
      "Epoch 4420/20000, Train Loss: 0.004971, Val Loss: 0.000184\n",
      "Epoch 4440/20000, Train Loss: 0.005140, Val Loss: 0.000102\n",
      "Epoch 4460/20000, Train Loss: 0.005144, Val Loss: 0.000133\n",
      "Epoch 4480/20000, Train Loss: 0.004955, Val Loss: 0.000142\n",
      "Epoch 4500/20000, Train Loss: 0.004995, Val Loss: 0.000153\n",
      "Epoch 4520/20000, Train Loss: 0.005168, Val Loss: 0.000089\n",
      "Epoch 4540/20000, Train Loss: 0.005066, Val Loss: 0.000071\n",
      "Epoch 4560/20000, Train Loss: 0.005120, Val Loss: 0.000045\n",
      "Epoch 4580/20000, Train Loss: 0.005103, Val Loss: 0.000117\n",
      "Epoch 4600/20000, Train Loss: 0.004971, Val Loss: 0.000093\n",
      "Epoch 4620/20000, Train Loss: 0.004972, Val Loss: 0.000140\n",
      "Epoch 4640/20000, Train Loss: 0.005135, Val Loss: 0.000177\n",
      "Epoch 4660/20000, Train Loss: 0.005022, Val Loss: 0.000090\n",
      "Epoch 4680/20000, Train Loss: 0.005037, Val Loss: 0.000095\n",
      "Epoch 4700/20000, Train Loss: 0.005028, Val Loss: 0.000130\n",
      "Epoch 4720/20000, Train Loss: 0.005013, Val Loss: 0.000109\n",
      "Epoch 4740/20000, Train Loss: 0.004978, Val Loss: 0.000163\n",
      "Epoch 4760/20000, Train Loss: 0.005005, Val Loss: 0.000074\n",
      "Epoch 4780/20000, Train Loss: 0.004946, Val Loss: 0.000144\n",
      "Epoch 4800/20000, Train Loss: 0.005026, Val Loss: 0.000112\n",
      "Epoch 4820/20000, Train Loss: 0.005051, Val Loss: 0.000100\n",
      "Epoch 4840/20000, Train Loss: 0.005002, Val Loss: 0.000207\n",
      "Epoch 4860/20000, Train Loss: 0.004933, Val Loss: 0.000042\n",
      "Epoch 4880/20000, Train Loss: 0.005029, Val Loss: 0.000100\n",
      "Epoch 4900/20000, Train Loss: 0.005014, Val Loss: 0.000110\n",
      "Epoch 4920/20000, Train Loss: 0.004888, Val Loss: 0.000222\n",
      "Epoch 4940/20000, Train Loss: 0.004989, Val Loss: 0.000261\n",
      "Epoch 4960/20000, Train Loss: 0.004965, Val Loss: 0.000100\n",
      "Epoch 4980/20000, Train Loss: 0.004994, Val Loss: 0.000058\n",
      "Epoch 5000/20000, Train Loss: 0.004897, Val Loss: 0.000080\n",
      "Epoch 5020/20000, Train Loss: 0.005066, Val Loss: 0.000066\n",
      "Epoch 5040/20000, Train Loss: 0.005012, Val Loss: 0.000123\n",
      "Epoch 5060/20000, Train Loss: 0.004973, Val Loss: 0.000068\n",
      "Epoch 5080/20000, Train Loss: 0.004896, Val Loss: 0.000099\n",
      "Epoch 5100/20000, Train Loss: 0.004837, Val Loss: 0.000160\n",
      "Epoch 5120/20000, Train Loss: 0.005028, Val Loss: 0.000090\n",
      "Epoch 5140/20000, Train Loss: 0.004894, Val Loss: 0.000147\n",
      "Epoch 5160/20000, Train Loss: 0.005018, Val Loss: 0.000118\n",
      "Epoch 5180/20000, Train Loss: 0.004859, Val Loss: 0.000092\n",
      "Epoch 5200/20000, Train Loss: 0.004926, Val Loss: 0.000070\n",
      "Epoch 5220/20000, Train Loss: 0.004982, Val Loss: 0.000100\n",
      "Epoch 5240/20000, Train Loss: 0.004971, Val Loss: 0.000086\n",
      "Epoch 5260/20000, Train Loss: 0.004842, Val Loss: 0.000145\n",
      "Epoch 5280/20000, Train Loss: 0.004949, Val Loss: 0.000138\n",
      "Epoch 5300/20000, Train Loss: 0.004978, Val Loss: 0.000112\n",
      "Epoch 5320/20000, Train Loss: 0.004908, Val Loss: 0.000093\n",
      "Epoch 5340/20000, Train Loss: 0.004927, Val Loss: 0.000068\n",
      "Epoch 5360/20000, Train Loss: 0.004907, Val Loss: 0.000114\n",
      "Epoch 5380/20000, Train Loss: 0.004935, Val Loss: 0.000106\n",
      "Epoch 5400/20000, Train Loss: 0.005017, Val Loss: 0.000104\n",
      "Epoch 5420/20000, Train Loss: 0.004979, Val Loss: 0.000123\n",
      "Epoch 5440/20000, Train Loss: 0.004846, Val Loss: 0.000194\n",
      "Epoch 5460/20000, Train Loss: 0.004971, Val Loss: 0.000228\n",
      "Epoch 5480/20000, Train Loss: 0.005123, Val Loss: 0.000151\n",
      "Epoch 5500/20000, Train Loss: 0.004863, Val Loss: 0.000080\n",
      "Epoch 5520/20000, Train Loss: 0.004956, Val Loss: 0.000057\n",
      "Epoch 5540/20000, Train Loss: 0.004871, Val Loss: 0.000110\n",
      "Epoch 5560/20000, Train Loss: 0.005071, Val Loss: 0.000123\n",
      "Epoch 5580/20000, Train Loss: 0.004901, Val Loss: 0.000104\n",
      "Epoch 5600/20000, Train Loss: 0.004863, Val Loss: 0.000263\n",
      "Epoch 5620/20000, Train Loss: 0.004889, Val Loss: 0.000298\n",
      "Epoch 5640/20000, Train Loss: 0.004809, Val Loss: 0.000146\n",
      "Epoch 5660/20000, Train Loss: 0.004993, Val Loss: 0.000136\n",
      "Epoch 5680/20000, Train Loss: 0.004979, Val Loss: 0.000054\n",
      "Epoch 5700/20000, Train Loss: 0.004813, Val Loss: 0.000066\n",
      "Epoch 5720/20000, Train Loss: 0.004870, Val Loss: 0.000091\n",
      "Epoch 5740/20000, Train Loss: 0.004905, Val Loss: 0.000072\n",
      "Epoch 5760/20000, Train Loss: 0.005137, Val Loss: 0.000076\n",
      "Epoch 5780/20000, Train Loss: 0.004808, Val Loss: 0.000094\n",
      "Epoch 5800/20000, Train Loss: 0.004923, Val Loss: 0.000113\n",
      "Epoch 5820/20000, Train Loss: 0.004855, Val Loss: 0.000163\n",
      "Epoch 5840/20000, Train Loss: 0.004892, Val Loss: 0.000219\n",
      "Epoch 5860/20000, Train Loss: 0.004853, Val Loss: 0.000074\n",
      "Epoch 5880/20000, Train Loss: 0.004863, Val Loss: 0.000147\n",
      "Epoch 5900/20000, Train Loss: 0.004946, Val Loss: 0.000090\n",
      "Epoch 5920/20000, Train Loss: 0.004829, Val Loss: 0.000110\n",
      "Epoch 5940/20000, Train Loss: 0.005026, Val Loss: 0.000133\n",
      "Epoch 5960/20000, Train Loss: 0.004909, Val Loss: 0.000101\n",
      "Epoch 5980/20000, Train Loss: 0.004848, Val Loss: 0.000104\n",
      "Epoch 6000/20000, Train Loss: 0.004932, Val Loss: 0.000087\n",
      "Epoch 6020/20000, Train Loss: 0.004984, Val Loss: 0.000098\n",
      "Epoch 6040/20000, Train Loss: 0.004861, Val Loss: 0.000090\n",
      "Epoch 6060/20000, Train Loss: 0.004909, Val Loss: 0.000049\n",
      "Epoch 6080/20000, Train Loss: 0.004951, Val Loss: 0.000071\n",
      "Epoch 6100/20000, Train Loss: 0.004741, Val Loss: 0.000148\n",
      "Epoch 6120/20000, Train Loss: 0.004840, Val Loss: 0.000115\n",
      "Epoch 6140/20000, Train Loss: 0.005022, Val Loss: 0.000038\n",
      "Epoch 6160/20000, Train Loss: 0.004763, Val Loss: 0.000107\n",
      "Epoch 6180/20000, Train Loss: 0.004859, Val Loss: 0.000137\n",
      "Epoch 6200/20000, Train Loss: 0.004925, Val Loss: 0.000127\n",
      "Epoch 6220/20000, Train Loss: 0.004857, Val Loss: 0.000078\n",
      "Epoch 6240/20000, Train Loss: 0.004814, Val Loss: 0.000138\n",
      "Epoch 6260/20000, Train Loss: 0.004822, Val Loss: 0.000102\n",
      "Epoch 6280/20000, Train Loss: 0.004891, Val Loss: 0.000114\n",
      "Epoch 6300/20000, Train Loss: 0.004813, Val Loss: 0.000156\n",
      "Epoch 6320/20000, Train Loss: 0.004864, Val Loss: 0.000101\n",
      "Epoch 6340/20000, Train Loss: 0.004808, Val Loss: 0.000141\n",
      "Epoch 6360/20000, Train Loss: 0.004796, Val Loss: 0.000059\n",
      "Epoch 6380/20000, Train Loss: 0.004899, Val Loss: 0.000135\n",
      "Epoch 6400/20000, Train Loss: 0.004936, Val Loss: 0.000074\n",
      "Epoch 6420/20000, Train Loss: 0.004836, Val Loss: 0.000127\n",
      "Epoch 6440/20000, Train Loss: 0.004891, Val Loss: 0.000111\n",
      "Epoch 6460/20000, Train Loss: 0.004903, Val Loss: 0.000176\n",
      "Epoch 6480/20000, Train Loss: 0.004974, Val Loss: 0.000095\n",
      "Epoch 6500/20000, Train Loss: 0.004947, Val Loss: 0.000076\n",
      "Epoch 6520/20000, Train Loss: 0.004809, Val Loss: 0.000091\n",
      "Epoch 6540/20000, Train Loss: 0.004704, Val Loss: 0.000057\n",
      "Epoch 6560/20000, Train Loss: 0.004797, Val Loss: 0.000069\n",
      "Epoch 6580/20000, Train Loss: 0.004967, Val Loss: 0.000081\n",
      "Epoch 6600/20000, Train Loss: 0.004891, Val Loss: 0.000182\n",
      "Epoch 6620/20000, Train Loss: 0.004891, Val Loss: 0.000077\n",
      "Epoch 6640/20000, Train Loss: 0.004798, Val Loss: 0.000146\n",
      "Epoch 6660/20000, Train Loss: 0.004830, Val Loss: 0.000181\n",
      "Epoch 6680/20000, Train Loss: 0.004864, Val Loss: 0.000126\n",
      "Epoch 6700/20000, Train Loss: 0.004862, Val Loss: 0.000135\n",
      "Epoch 6720/20000, Train Loss: 0.004858, Val Loss: 0.000100\n",
      "Epoch 6740/20000, Train Loss: 0.004907, Val Loss: 0.000063\n",
      "Epoch 6760/20000, Train Loss: 0.004884, Val Loss: 0.000280\n",
      "Epoch 6780/20000, Train Loss: 0.004826, Val Loss: 0.000154\n",
      "Epoch 6800/20000, Train Loss: 0.004737, Val Loss: 0.000059\n",
      "Epoch 6820/20000, Train Loss: 0.004924, Val Loss: 0.000063\n",
      "Epoch 6840/20000, Train Loss: 0.004873, Val Loss: 0.000141\n",
      "Epoch 6860/20000, Train Loss: 0.004884, Val Loss: 0.000095\n",
      "Epoch 6880/20000, Train Loss: 0.004866, Val Loss: 0.000116\n",
      "Epoch 6900/20000, Train Loss: 0.004802, Val Loss: 0.000112\n",
      "Epoch 6920/20000, Train Loss: 0.004800, Val Loss: 0.000061\n",
      "Epoch 6940/20000, Train Loss: 0.004817, Val Loss: 0.000137\n",
      "Epoch 6960/20000, Train Loss: 0.004874, Val Loss: 0.000124\n",
      "Epoch 6980/20000, Train Loss: 0.004838, Val Loss: 0.000091\n",
      "Epoch 7000/20000, Train Loss: 0.004900, Val Loss: 0.000129\n",
      "Epoch 7020/20000, Train Loss: 0.004835, Val Loss: 0.000199\n",
      "Epoch 7040/20000, Train Loss: 0.004851, Val Loss: 0.000115\n",
      "Epoch 7060/20000, Train Loss: 0.004866, Val Loss: 0.000084\n",
      "Epoch 7080/20000, Train Loss: 0.004844, Val Loss: 0.000074\n",
      "Epoch 7100/20000, Train Loss: 0.004818, Val Loss: 0.000124\n",
      "Epoch 7120/20000, Train Loss: 0.004835, Val Loss: 0.000144\n",
      "Epoch 7140/20000, Train Loss: 0.004739, Val Loss: 0.000127\n",
      "Epoch 7160/20000, Train Loss: 0.004875, Val Loss: 0.000053\n",
      "Epoch 7180/20000, Train Loss: 0.004769, Val Loss: 0.000082\n",
      "Epoch 7200/20000, Train Loss: 0.004851, Val Loss: 0.000093\n",
      "Epoch 7220/20000, Train Loss: 0.004712, Val Loss: 0.000202\n",
      "Epoch 7240/20000, Train Loss: 0.004715, Val Loss: 0.000094\n",
      "Epoch 7260/20000, Train Loss: 0.004770, Val Loss: 0.000075\n",
      "Epoch 7280/20000, Train Loss: 0.004853, Val Loss: 0.000200\n",
      "Epoch 7300/20000, Train Loss: 0.004876, Val Loss: 0.000104\n",
      "Epoch 7320/20000, Train Loss: 0.004793, Val Loss: 0.000058\n",
      "Epoch 7340/20000, Train Loss: 0.004773, Val Loss: 0.000100\n",
      "Epoch 7360/20000, Train Loss: 0.004908, Val Loss: 0.000152\n",
      "Epoch 7380/20000, Train Loss: 0.004859, Val Loss: 0.000132\n",
      "Epoch 7400/20000, Train Loss: 0.004796, Val Loss: 0.000170\n",
      "Epoch 7420/20000, Train Loss: 0.004931, Val Loss: 0.000087\n",
      "Epoch 7440/20000, Train Loss: 0.004849, Val Loss: 0.000096\n",
      "Epoch 7460/20000, Train Loss: 0.004886, Val Loss: 0.000114\n",
      "Epoch 7480/20000, Train Loss: 0.004683, Val Loss: 0.000136\n",
      "Epoch 7500/20000, Train Loss: 0.004812, Val Loss: 0.000076\n",
      "Epoch 7520/20000, Train Loss: 0.004753, Val Loss: 0.000084\n",
      "Epoch 7540/20000, Train Loss: 0.004831, Val Loss: 0.000165\n",
      "Epoch 7560/20000, Train Loss: 0.004891, Val Loss: 0.000185\n",
      "Epoch 7580/20000, Train Loss: 0.004758, Val Loss: 0.000140\n",
      "Epoch 7600/20000, Train Loss: 0.004706, Val Loss: 0.000133\n",
      "Epoch 7620/20000, Train Loss: 0.004755, Val Loss: 0.000078\n",
      "Epoch 7640/20000, Train Loss: 0.004825, Val Loss: 0.000082\n",
      "Epoch 7660/20000, Train Loss: 0.004761, Val Loss: 0.000210\n",
      "Epoch 7680/20000, Train Loss: 0.004815, Val Loss: 0.000121\n",
      "Epoch 7700/20000, Train Loss: 0.004828, Val Loss: 0.000118\n",
      "Epoch 7720/20000, Train Loss: 0.004769, Val Loss: 0.000163\n",
      "Epoch 7740/20000, Train Loss: 0.004842, Val Loss: 0.000088\n",
      "Epoch 7760/20000, Train Loss: 0.004839, Val Loss: 0.000095\n",
      "Epoch 7780/20000, Train Loss: 0.004676, Val Loss: 0.000109\n",
      "Epoch 7800/20000, Train Loss: 0.004868, Val Loss: 0.000113\n",
      "Epoch 7820/20000, Train Loss: 0.004939, Val Loss: 0.000089\n",
      "Epoch 7840/20000, Train Loss: 0.004841, Val Loss: 0.000159\n",
      "Epoch 7860/20000, Train Loss: 0.004762, Val Loss: 0.000087\n",
      "Epoch 7880/20000, Train Loss: 0.004812, Val Loss: 0.000165\n",
      "Epoch 7900/20000, Train Loss: 0.004855, Val Loss: 0.000196\n",
      "Epoch 7920/20000, Train Loss: 0.004755, Val Loss: 0.000136\n",
      "Epoch 7940/20000, Train Loss: 0.004816, Val Loss: 0.000082\n",
      "Epoch 7960/20000, Train Loss: 0.004725, Val Loss: 0.000094\n",
      "Epoch 7980/20000, Train Loss: 0.004722, Val Loss: 0.000079\n",
      "Epoch 8000/20000, Train Loss: 0.004909, Val Loss: 0.000132\n",
      "Epoch 8020/20000, Train Loss: 0.004675, Val Loss: 0.000092\n",
      "Epoch 8040/20000, Train Loss: 0.004756, Val Loss: 0.000112\n",
      "Epoch 8060/20000, Train Loss: 0.004864, Val Loss: 0.000049\n",
      "Epoch 8080/20000, Train Loss: 0.004835, Val Loss: 0.000116\n",
      "Epoch 8100/20000, Train Loss: 0.004843, Val Loss: 0.000076\n",
      "Epoch 8120/20000, Train Loss: 0.004846, Val Loss: 0.000063\n",
      "Epoch 8140/20000, Train Loss: 0.004821, Val Loss: 0.000131\n",
      "Epoch 8160/20000, Train Loss: 0.004882, Val Loss: 0.000122\n",
      "Epoch 8180/20000, Train Loss: 0.004706, Val Loss: 0.000106\n",
      "Epoch 8200/20000, Train Loss: 0.004884, Val Loss: 0.000046\n",
      "Epoch 8220/20000, Train Loss: 0.004823, Val Loss: 0.000181\n",
      "Epoch 8240/20000, Train Loss: 0.004928, Val Loss: 0.000131\n",
      "Epoch 8260/20000, Train Loss: 0.004708, Val Loss: 0.000095\n",
      "Epoch 8280/20000, Train Loss: 0.004754, Val Loss: 0.000123\n",
      "Epoch 8300/20000, Train Loss: 0.004654, Val Loss: 0.000096\n",
      "Epoch 8320/20000, Train Loss: 0.004832, Val Loss: 0.000082\n",
      "Epoch 8340/20000, Train Loss: 0.004799, Val Loss: 0.000071\n",
      "Epoch 8360/20000, Train Loss: 0.004816, Val Loss: 0.000124\n",
      "Epoch 8380/20000, Train Loss: 0.004820, Val Loss: 0.000187\n",
      "Epoch 8400/20000, Train Loss: 0.004750, Val Loss: 0.000038\n",
      "Epoch 8420/20000, Train Loss: 0.004813, Val Loss: 0.000087\n",
      "Epoch 8440/20000, Train Loss: 0.004782, Val Loss: 0.000170\n",
      "Epoch 8460/20000, Train Loss: 0.004894, Val Loss: 0.000106\n",
      "Epoch 8480/20000, Train Loss: 0.004645, Val Loss: 0.000144\n",
      "Epoch 8500/20000, Train Loss: 0.004805, Val Loss: 0.000077\n",
      "Epoch 8520/20000, Train Loss: 0.004796, Val Loss: 0.000049\n",
      "Epoch 8540/20000, Train Loss: 0.004948, Val Loss: 0.000171\n",
      "Epoch 8560/20000, Train Loss: 0.004703, Val Loss: 0.000115\n",
      "Epoch 8580/20000, Train Loss: 0.004740, Val Loss: 0.000092\n",
      "Epoch 8600/20000, Train Loss: 0.004742, Val Loss: 0.000165\n",
      "Epoch 8620/20000, Train Loss: 0.004820, Val Loss: 0.000198\n",
      "Epoch 8640/20000, Train Loss: 0.004794, Val Loss: 0.000061\n",
      "Epoch 8660/20000, Train Loss: 0.004760, Val Loss: 0.000079\n",
      "Epoch 8680/20000, Train Loss: 0.004683, Val Loss: 0.000079\n",
      "Epoch 8700/20000, Train Loss: 0.004580, Val Loss: 0.000121\n",
      "Epoch 8720/20000, Train Loss: 0.004724, Val Loss: 0.000099\n",
      "Epoch 8740/20000, Train Loss: 0.004710, Val Loss: 0.000103\n",
      "Epoch 8760/20000, Train Loss: 0.004869, Val Loss: 0.000110\n",
      "Epoch 8780/20000, Train Loss: 0.004840, Val Loss: 0.000094\n",
      "Epoch 8800/20000, Train Loss: 0.004789, Val Loss: 0.000141\n",
      "Epoch 8820/20000, Train Loss: 0.004698, Val Loss: 0.000047\n",
      "Epoch 8840/20000, Train Loss: 0.004734, Val Loss: 0.000189\n",
      "Epoch 8860/20000, Train Loss: 0.004875, Val Loss: 0.000134\n",
      "Epoch 8880/20000, Train Loss: 0.004736, Val Loss: 0.000131\n",
      "Epoch 8900/20000, Train Loss: 0.004818, Val Loss: 0.000105\n",
      "Epoch 8920/20000, Train Loss: 0.004813, Val Loss: 0.000098\n",
      "Epoch 8940/20000, Train Loss: 0.004798, Val Loss: 0.000117\n",
      "Epoch 8960/20000, Train Loss: 0.004730, Val Loss: 0.000126\n",
      "Epoch 8980/20000, Train Loss: 0.004716, Val Loss: 0.000115\n",
      "Epoch 9000/20000, Train Loss: 0.004728, Val Loss: 0.000073\n",
      "Epoch 9020/20000, Train Loss: 0.004778, Val Loss: 0.000104\n",
      "Epoch 9040/20000, Train Loss: 0.004683, Val Loss: 0.000097\n",
      "Epoch 9060/20000, Train Loss: 0.004756, Val Loss: 0.000049\n",
      "Epoch 9080/20000, Train Loss: 0.004729, Val Loss: 0.000156\n",
      "Epoch 9100/20000, Train Loss: 0.004802, Val Loss: 0.000110\n",
      "Epoch 9120/20000, Train Loss: 0.004705, Val Loss: 0.000081\n",
      "Epoch 9140/20000, Train Loss: 0.004782, Val Loss: 0.000061\n",
      "Epoch 9160/20000, Train Loss: 0.004785, Val Loss: 0.000102\n",
      "Epoch 9180/20000, Train Loss: 0.004850, Val Loss: 0.000137\n",
      "Epoch 9200/20000, Train Loss: 0.004748, Val Loss: 0.000064\n",
      "Epoch 9220/20000, Train Loss: 0.004770, Val Loss: 0.000108\n",
      "Epoch 9240/20000, Train Loss: 0.004744, Val Loss: 0.000089\n",
      "Epoch 9260/20000, Train Loss: 0.004715, Val Loss: 0.000074\n",
      "Epoch 9280/20000, Train Loss: 0.004728, Val Loss: 0.000230\n",
      "Epoch 9300/20000, Train Loss: 0.004696, Val Loss: 0.000141\n",
      "Epoch 9320/20000, Train Loss: 0.004850, Val Loss: 0.000060\n",
      "Epoch 9340/20000, Train Loss: 0.004814, Val Loss: 0.000106\n",
      "Epoch 9360/20000, Train Loss: 0.004734, Val Loss: 0.000047\n",
      "Epoch 9380/20000, Train Loss: 0.004751, Val Loss: 0.000091\n",
      "Epoch 9400/20000, Train Loss: 0.004693, Val Loss: 0.000114\n",
      "Epoch 9420/20000, Train Loss: 0.004830, Val Loss: 0.000117\n",
      "Epoch 9440/20000, Train Loss: 0.004621, Val Loss: 0.000088\n",
      "Epoch 9460/20000, Train Loss: 0.004730, Val Loss: 0.000113\n",
      "Epoch 9480/20000, Train Loss: 0.004669, Val Loss: 0.000115\n",
      "Epoch 9500/20000, Train Loss: 0.004778, Val Loss: 0.000089\n",
      "Epoch 9520/20000, Train Loss: 0.004630, Val Loss: 0.000150\n",
      "Epoch 9540/20000, Train Loss: 0.004761, Val Loss: 0.000072\n",
      "Epoch 9560/20000, Train Loss: 0.004719, Val Loss: 0.000117\n",
      "Epoch 9580/20000, Train Loss: 0.004677, Val Loss: 0.000074\n",
      "Epoch 9600/20000, Train Loss: 0.004693, Val Loss: 0.000130\n",
      "Epoch 9620/20000, Train Loss: 0.004775, Val Loss: 0.000076\n",
      "Epoch 9640/20000, Train Loss: 0.004729, Val Loss: 0.000133\n",
      "Epoch 9660/20000, Train Loss: 0.004842, Val Loss: 0.000200\n",
      "Epoch 9680/20000, Train Loss: 0.004724, Val Loss: 0.000045\n",
      "Epoch 9700/20000, Train Loss: 0.004854, Val Loss: 0.000116\n",
      "Epoch 9720/20000, Train Loss: 0.004690, Val Loss: 0.000131\n",
      "Epoch 9740/20000, Train Loss: 0.004782, Val Loss: 0.000133\n",
      "Epoch 9760/20000, Train Loss: 0.004813, Val Loss: 0.000102\n",
      "Epoch 9780/20000, Train Loss: 0.004759, Val Loss: 0.000053\n",
      "Epoch 9800/20000, Train Loss: 0.004815, Val Loss: 0.000153\n",
      "Epoch 9820/20000, Train Loss: 0.004699, Val Loss: 0.000046\n",
      "Epoch 9840/20000, Train Loss: 0.004731, Val Loss: 0.000096\n",
      "Epoch 9860/20000, Train Loss: 0.004662, Val Loss: 0.000179\n",
      "Epoch 9880/20000, Train Loss: 0.004670, Val Loss: 0.000122\n",
      "Epoch 9900/20000, Train Loss: 0.004744, Val Loss: 0.000059\n",
      "Epoch 9920/20000, Train Loss: 0.004722, Val Loss: 0.000157\n",
      "Epoch 9940/20000, Train Loss: 0.004829, Val Loss: 0.000110\n",
      "Epoch 9960/20000, Train Loss: 0.004731, Val Loss: 0.000108\n",
      "Epoch 9980/20000, Train Loss: 0.004718, Val Loss: 0.000142\n",
      "Epoch 10000/20000, Train Loss: 0.004599, Val Loss: 0.000088\n",
      "Epoch 10020/20000, Train Loss: 0.004804, Val Loss: 0.000070\n",
      "Epoch 10040/20000, Train Loss: 0.004713, Val Loss: 0.000069\n",
      "Epoch 10060/20000, Train Loss: 0.004712, Val Loss: 0.000125\n",
      "Epoch 10080/20000, Train Loss: 0.004840, Val Loss: 0.000060\n",
      "Epoch 10100/20000, Train Loss: 0.004836, Val Loss: 0.000052\n",
      "Epoch 10120/20000, Train Loss: 0.004733, Val Loss: 0.000107\n",
      "Epoch 10140/20000, Train Loss: 0.004910, Val Loss: 0.000043\n",
      "Epoch 10160/20000, Train Loss: 0.004705, Val Loss: 0.000095\n",
      "Epoch 10180/20000, Train Loss: 0.004664, Val Loss: 0.000060\n",
      "Epoch 10200/20000, Train Loss: 0.004804, Val Loss: 0.000102\n",
      "Epoch 10220/20000, Train Loss: 0.004646, Val Loss: 0.000057\n",
      "Epoch 10240/20000, Train Loss: 0.004600, Val Loss: 0.000110\n",
      "Epoch 10260/20000, Train Loss: 0.004662, Val Loss: 0.000073\n",
      "Epoch 10280/20000, Train Loss: 0.004763, Val Loss: 0.000115\n",
      "Epoch 10300/20000, Train Loss: 0.004742, Val Loss: 0.000094\n",
      "Epoch 10320/20000, Train Loss: 0.004812, Val Loss: 0.000113\n",
      "Epoch 10340/20000, Train Loss: 0.004721, Val Loss: 0.000079\n",
      "Epoch 10360/20000, Train Loss: 0.004732, Val Loss: 0.000132\n",
      "Epoch 10380/20000, Train Loss: 0.004754, Val Loss: 0.000115\n",
      "Epoch 10400/20000, Train Loss: 0.004749, Val Loss: 0.000093\n",
      "Epoch 10420/20000, Train Loss: 0.004766, Val Loss: 0.000287\n",
      "Epoch 10440/20000, Train Loss: 0.004768, Val Loss: 0.000055\n",
      "Epoch 10460/20000, Train Loss: 0.004824, Val Loss: 0.000127\n",
      "Epoch 10480/20000, Train Loss: 0.004758, Val Loss: 0.000091\n",
      "Epoch 10500/20000, Train Loss: 0.004824, Val Loss: 0.000176\n",
      "Epoch 10520/20000, Train Loss: 0.004690, Val Loss: 0.000053\n",
      "Epoch 10540/20000, Train Loss: 0.004682, Val Loss: 0.000079\n",
      "Epoch 10560/20000, Train Loss: 0.004679, Val Loss: 0.000122\n",
      "Epoch 10580/20000, Train Loss: 0.004747, Val Loss: 0.000074\n",
      "Epoch 10600/20000, Train Loss: 0.004788, Val Loss: 0.000101\n",
      "Epoch 10620/20000, Train Loss: 0.004721, Val Loss: 0.000088\n",
      "Epoch 10640/20000, Train Loss: 0.004676, Val Loss: 0.000060\n",
      "Epoch 10660/20000, Train Loss: 0.004671, Val Loss: 0.000126\n",
      "Epoch 10680/20000, Train Loss: 0.004749, Val Loss: 0.000073\n",
      "Epoch 10700/20000, Train Loss: 0.004632, Val Loss: 0.000137\n",
      "Epoch 10720/20000, Train Loss: 0.004755, Val Loss: 0.000133\n",
      "Epoch 10740/20000, Train Loss: 0.004702, Val Loss: 0.000089\n",
      "Epoch 10760/20000, Train Loss: 0.004789, Val Loss: 0.000110\n",
      "Epoch 10780/20000, Train Loss: 0.004709, Val Loss: 0.000122\n",
      "Epoch 10800/20000, Train Loss: 0.004742, Val Loss: 0.000124\n",
      "Epoch 10820/20000, Train Loss: 0.004668, Val Loss: 0.000086\n",
      "Epoch 10840/20000, Train Loss: 0.004630, Val Loss: 0.000088\n",
      "Epoch 10860/20000, Train Loss: 0.004783, Val Loss: 0.000141\n",
      "Epoch 10880/20000, Train Loss: 0.004542, Val Loss: 0.000136\n",
      "Epoch 10900/20000, Train Loss: 0.004673, Val Loss: 0.000165\n",
      "Epoch 10920/20000, Train Loss: 0.004771, Val Loss: 0.000105\n",
      "Epoch 10940/20000, Train Loss: 0.004740, Val Loss: 0.000178\n",
      "Epoch 10960/20000, Train Loss: 0.004674, Val Loss: 0.000087\n",
      "Epoch 10980/20000, Train Loss: 0.004802, Val Loss: 0.000078\n",
      "Epoch 11000/20000, Train Loss: 0.004709, Val Loss: 0.000152\n",
      "Epoch 11020/20000, Train Loss: 0.004719, Val Loss: 0.000113\n",
      "Epoch 11040/20000, Train Loss: 0.004720, Val Loss: 0.000183\n",
      "Epoch 11060/20000, Train Loss: 0.004590, Val Loss: 0.000069\n",
      "Epoch 11080/20000, Train Loss: 0.004680, Val Loss: 0.000151\n",
      "Epoch 11100/20000, Train Loss: 0.004636, Val Loss: 0.000099\n",
      "Epoch 11120/20000, Train Loss: 0.004535, Val Loss: 0.000085\n",
      "Epoch 11140/20000, Train Loss: 0.004700, Val Loss: 0.000074\n",
      "Epoch 11160/20000, Train Loss: 0.004771, Val Loss: 0.000129\n",
      "Epoch 11180/20000, Train Loss: 0.004778, Val Loss: 0.000093\n",
      "Epoch 11200/20000, Train Loss: 0.004591, Val Loss: 0.000125\n",
      "Epoch 11220/20000, Train Loss: 0.004603, Val Loss: 0.000115\n",
      "Epoch 11240/20000, Train Loss: 0.004653, Val Loss: 0.000206\n",
      "Epoch 11260/20000, Train Loss: 0.004708, Val Loss: 0.000160\n",
      "Epoch 11280/20000, Train Loss: 0.004737, Val Loss: 0.000072\n",
      "Epoch 11300/20000, Train Loss: 0.004619, Val Loss: 0.000147\n",
      "Epoch 11320/20000, Train Loss: 0.004687, Val Loss: 0.000115\n",
      "Epoch 11340/20000, Train Loss: 0.004718, Val Loss: 0.000120\n",
      "Epoch 11360/20000, Train Loss: 0.004569, Val Loss: 0.000080\n",
      "Epoch 11380/20000, Train Loss: 0.004645, Val Loss: 0.000125\n",
      "Epoch 11400/20000, Train Loss: 0.004751, Val Loss: 0.000054\n",
      "Epoch 11420/20000, Train Loss: 0.004642, Val Loss: 0.000103\n",
      "Epoch 11440/20000, Train Loss: 0.004619, Val Loss: 0.000061\n",
      "Epoch 11460/20000, Train Loss: 0.004736, Val Loss: 0.000096\n",
      "Epoch 11480/20000, Train Loss: 0.004847, Val Loss: 0.000089\n",
      "Epoch 11500/20000, Train Loss: 0.004732, Val Loss: 0.000177\n",
      "Epoch 11520/20000, Train Loss: 0.004766, Val Loss: 0.000065\n",
      "Epoch 11540/20000, Train Loss: 0.004816, Val Loss: 0.000156\n",
      "Epoch 11560/20000, Train Loss: 0.004645, Val Loss: 0.000057\n",
      "Epoch 11580/20000, Train Loss: 0.004615, Val Loss: 0.000218\n",
      "Epoch 11600/20000, Train Loss: 0.004648, Val Loss: 0.000104\n",
      "Epoch 11620/20000, Train Loss: 0.004767, Val Loss: 0.000112\n",
      "Epoch 11640/20000, Train Loss: 0.004685, Val Loss: 0.000179\n",
      "Epoch 11660/20000, Train Loss: 0.004773, Val Loss: 0.000055\n",
      "Epoch 11680/20000, Train Loss: 0.004695, Val Loss: 0.000047\n",
      "Epoch 11700/20000, Train Loss: 0.004672, Val Loss: 0.000099\n",
      "Epoch 11720/20000, Train Loss: 0.004702, Val Loss: 0.000042\n",
      "Epoch 11740/20000, Train Loss: 0.004577, Val Loss: 0.000157\n",
      "Epoch 11760/20000, Train Loss: 0.004641, Val Loss: 0.000056\n",
      "Epoch 11780/20000, Train Loss: 0.004730, Val Loss: 0.000037\n",
      "Epoch 11800/20000, Train Loss: 0.004718, Val Loss: 0.000080\n",
      "Epoch 11820/20000, Train Loss: 0.004646, Val Loss: 0.000205\n",
      "Epoch 11840/20000, Train Loss: 0.004656, Val Loss: 0.000089\n",
      "Epoch 11860/20000, Train Loss: 0.004736, Val Loss: 0.000074\n",
      "Epoch 11880/20000, Train Loss: 0.004619, Val Loss: 0.000065\n",
      "Epoch 11900/20000, Train Loss: 0.004627, Val Loss: 0.000129\n",
      "Epoch 11920/20000, Train Loss: 0.004629, Val Loss: 0.000144\n",
      "Epoch 11940/20000, Train Loss: 0.004706, Val Loss: 0.000188\n",
      "Epoch 11960/20000, Train Loss: 0.004742, Val Loss: 0.000050\n",
      "Epoch 11980/20000, Train Loss: 0.004768, Val Loss: 0.000200\n",
      "Epoch 12000/20000, Train Loss: 0.004515, Val Loss: 0.000170\n",
      "Epoch 12020/20000, Train Loss: 0.004616, Val Loss: 0.000115\n",
      "Epoch 12040/20000, Train Loss: 0.004649, Val Loss: 0.000165\n",
      "Epoch 12060/20000, Train Loss: 0.004694, Val Loss: 0.000053\n",
      "Epoch 12080/20000, Train Loss: 0.004742, Val Loss: 0.000059\n",
      "Epoch 12100/20000, Train Loss: 0.004638, Val Loss: 0.000073\n",
      "Epoch 12120/20000, Train Loss: 0.004559, Val Loss: 0.000140\n",
      "Epoch 12140/20000, Train Loss: 0.004647, Val Loss: 0.000094\n",
      "Epoch 12160/20000, Train Loss: 0.004706, Val Loss: 0.000085\n",
      "Epoch 12180/20000, Train Loss: 0.004706, Val Loss: 0.000084\n",
      "Epoch 12200/20000, Train Loss: 0.004565, Val Loss: 0.000107\n",
      "Epoch 12220/20000, Train Loss: 0.004753, Val Loss: 0.000124\n",
      "Epoch 12240/20000, Train Loss: 0.004520, Val Loss: 0.000119\n",
      "Epoch 12260/20000, Train Loss: 0.004542, Val Loss: 0.000097\n",
      "Epoch 12280/20000, Train Loss: 0.004778, Val Loss: 0.000084\n",
      "Epoch 12300/20000, Train Loss: 0.004806, Val Loss: 0.000100\n",
      "Epoch 12320/20000, Train Loss: 0.004623, Val Loss: 0.000108\n",
      "Epoch 12340/20000, Train Loss: 0.004498, Val Loss: 0.000062\n",
      "Epoch 12360/20000, Train Loss: 0.004544, Val Loss: 0.000084\n",
      "Epoch 12380/20000, Train Loss: 0.004704, Val Loss: 0.000114\n",
      "Epoch 12400/20000, Train Loss: 0.004569, Val Loss: 0.000106\n",
      "Epoch 12420/20000, Train Loss: 0.004751, Val Loss: 0.000065\n",
      "Epoch 12440/20000, Train Loss: 0.004773, Val Loss: 0.000060\n",
      "Epoch 12460/20000, Train Loss: 0.004778, Val Loss: 0.000062\n",
      "Epoch 12480/20000, Train Loss: 0.004772, Val Loss: 0.000109\n",
      "Epoch 12500/20000, Train Loss: 0.004737, Val Loss: 0.000075\n",
      "Epoch 12520/20000, Train Loss: 0.004651, Val Loss: 0.000038\n",
      "Epoch 12540/20000, Train Loss: 0.004606, Val Loss: 0.000059\n",
      "Epoch 12560/20000, Train Loss: 0.004690, Val Loss: 0.000072\n",
      "Epoch 12580/20000, Train Loss: 0.004755, Val Loss: 0.000114\n",
      "Epoch 12600/20000, Train Loss: 0.004593, Val Loss: 0.000053\n",
      "Epoch 12620/20000, Train Loss: 0.004700, Val Loss: 0.000081\n",
      "Epoch 12640/20000, Train Loss: 0.004724, Val Loss: 0.000084\n",
      "Epoch 12660/20000, Train Loss: 0.004588, Val Loss: 0.000153\n",
      "Epoch 12680/20000, Train Loss: 0.004579, Val Loss: 0.000078\n",
      "Epoch 12700/20000, Train Loss: 0.004646, Val Loss: 0.000100\n",
      "Epoch 12720/20000, Train Loss: 0.004731, Val Loss: 0.000108\n",
      "Epoch 12740/20000, Train Loss: 0.004635, Val Loss: 0.000181\n",
      "Epoch 12760/20000, Train Loss: 0.004682, Val Loss: 0.000081\n",
      "Epoch 12780/20000, Train Loss: 0.004632, Val Loss: 0.000066\n",
      "Epoch 12800/20000, Train Loss: 0.004582, Val Loss: 0.000047\n",
      "Epoch 12820/20000, Train Loss: 0.004616, Val Loss: 0.000059\n",
      "Epoch 12840/20000, Train Loss: 0.004719, Val Loss: 0.000099\n",
      "Epoch 12860/20000, Train Loss: 0.004621, Val Loss: 0.000156\n",
      "Epoch 12880/20000, Train Loss: 0.004801, Val Loss: 0.000058\n",
      "Epoch 12900/20000, Train Loss: 0.004655, Val Loss: 0.000154\n",
      "Epoch 12920/20000, Train Loss: 0.004702, Val Loss: 0.000091\n",
      "Epoch 12940/20000, Train Loss: 0.004638, Val Loss: 0.000142\n",
      "Epoch 12960/20000, Train Loss: 0.004692, Val Loss: 0.000105\n",
      "Epoch 12980/20000, Train Loss: 0.004663, Val Loss: 0.000062\n",
      "Epoch 13000/20000, Train Loss: 0.004602, Val Loss: 0.000067\n",
      "Epoch 13020/20000, Train Loss: 0.004787, Val Loss: 0.000092\n",
      "Epoch 13040/20000, Train Loss: 0.004712, Val Loss: 0.000104\n",
      "Epoch 13060/20000, Train Loss: 0.004681, Val Loss: 0.000101\n",
      "Epoch 13080/20000, Train Loss: 0.004742, Val Loss: 0.000066\n",
      "Epoch 13100/20000, Train Loss: 0.004645, Val Loss: 0.000074\n",
      "Epoch 13120/20000, Train Loss: 0.004606, Val Loss: 0.000049\n",
      "Epoch 13140/20000, Train Loss: 0.004641, Val Loss: 0.000221\n",
      "Epoch 13160/20000, Train Loss: 0.004696, Val Loss: 0.000074\n",
      "Epoch 13180/20000, Train Loss: 0.004639, Val Loss: 0.000092\n",
      "Epoch 13200/20000, Train Loss: 0.004669, Val Loss: 0.000161\n",
      "Epoch 13220/20000, Train Loss: 0.004609, Val Loss: 0.000162\n",
      "Epoch 13240/20000, Train Loss: 0.004701, Val Loss: 0.000168\n",
      "Epoch 13260/20000, Train Loss: 0.004794, Val Loss: 0.000123\n",
      "Epoch 13280/20000, Train Loss: 0.004591, Val Loss: 0.000059\n",
      "Epoch 13300/20000, Train Loss: 0.004680, Val Loss: 0.000101\n",
      "Epoch 13320/20000, Train Loss: 0.004672, Val Loss: 0.000085\n",
      "Epoch 13340/20000, Train Loss: 0.004652, Val Loss: 0.000064\n",
      "Epoch 13360/20000, Train Loss: 0.004700, Val Loss: 0.000074\n",
      "Epoch 13380/20000, Train Loss: 0.004687, Val Loss: 0.000125\n",
      "Epoch 13400/20000, Train Loss: 0.004643, Val Loss: 0.000071\n",
      "Epoch 13420/20000, Train Loss: 0.004707, Val Loss: 0.000073\n",
      "Epoch 13440/20000, Train Loss: 0.004738, Val Loss: 0.000054\n",
      "Epoch 13460/20000, Train Loss: 0.004620, Val Loss: 0.000056\n",
      "Epoch 13480/20000, Train Loss: 0.004578, Val Loss: 0.000113\n",
      "Epoch 13500/20000, Train Loss: 0.004585, Val Loss: 0.000089\n",
      "Epoch 13520/20000, Train Loss: 0.004702, Val Loss: 0.000107\n",
      "Epoch 13540/20000, Train Loss: 0.004552, Val Loss: 0.000059\n",
      "Epoch 13560/20000, Train Loss: 0.004581, Val Loss: 0.000078\n",
      "Epoch 13580/20000, Train Loss: 0.004707, Val Loss: 0.000122\n",
      "Epoch 13600/20000, Train Loss: 0.004563, Val Loss: 0.000044\n",
      "Epoch 13620/20000, Train Loss: 0.004652, Val Loss: 0.000064\n",
      "Epoch 13640/20000, Train Loss: 0.004674, Val Loss: 0.000092\n",
      "Epoch 13660/20000, Train Loss: 0.004719, Val Loss: 0.000093\n",
      "Epoch 13680/20000, Train Loss: 0.004744, Val Loss: 0.000111\n",
      "Epoch 13700/20000, Train Loss: 0.004749, Val Loss: 0.000096\n",
      "Epoch 13720/20000, Train Loss: 0.004617, Val Loss: 0.000060\n",
      "Epoch 13740/20000, Train Loss: 0.004592, Val Loss: 0.000134\n",
      "Epoch 13760/20000, Train Loss: 0.004645, Val Loss: 0.000080\n",
      "Epoch 13780/20000, Train Loss: 0.004690, Val Loss: 0.000061\n",
      "Epoch 13800/20000, Train Loss: 0.004703, Val Loss: 0.000065\n",
      "Epoch 13820/20000, Train Loss: 0.004705, Val Loss: 0.000069\n",
      "Epoch 13840/20000, Train Loss: 0.004626, Val Loss: 0.000107\n",
      "Epoch 13860/20000, Train Loss: 0.004638, Val Loss: 0.000087\n",
      "Epoch 13880/20000, Train Loss: 0.004614, Val Loss: 0.000059\n",
      "Epoch 13900/20000, Train Loss: 0.004543, Val Loss: 0.000076\n",
      "Epoch 13920/20000, Train Loss: 0.004608, Val Loss: 0.000119\n",
      "Epoch 13940/20000, Train Loss: 0.004579, Val Loss: 0.000111\n",
      "Epoch 13960/20000, Train Loss: 0.004702, Val Loss: 0.000069\n",
      "Epoch 13980/20000, Train Loss: 0.004562, Val Loss: 0.000096\n",
      "Epoch 14000/20000, Train Loss: 0.004707, Val Loss: 0.000087\n",
      "Epoch 14020/20000, Train Loss: 0.004623, Val Loss: 0.000066\n",
      "Epoch 14040/20000, Train Loss: 0.004628, Val Loss: 0.000081\n",
      "Epoch 14060/20000, Train Loss: 0.004633, Val Loss: 0.000201\n",
      "Epoch 14080/20000, Train Loss: 0.004774, Val Loss: 0.000060\n",
      "Epoch 14100/20000, Train Loss: 0.004620, Val Loss: 0.000117\n",
      "Epoch 14120/20000, Train Loss: 0.004614, Val Loss: 0.000155\n",
      "Epoch 14140/20000, Train Loss: 0.004631, Val Loss: 0.000080\n",
      "Epoch 14160/20000, Train Loss: 0.004648, Val Loss: 0.000197\n",
      "Epoch 14180/20000, Train Loss: 0.004582, Val Loss: 0.000115\n",
      "Epoch 14200/20000, Train Loss: 0.004680, Val Loss: 0.000113\n",
      "Epoch 14220/20000, Train Loss: 0.004725, Val Loss: 0.000116\n",
      "Epoch 14240/20000, Train Loss: 0.004561, Val Loss: 0.000093\n",
      "Epoch 14260/20000, Train Loss: 0.004725, Val Loss: 0.000133\n",
      "Epoch 14280/20000, Train Loss: 0.004599, Val Loss: 0.000121\n",
      "Epoch 14300/20000, Train Loss: 0.004627, Val Loss: 0.000137\n",
      "Epoch 14320/20000, Train Loss: 0.004662, Val Loss: 0.000106\n",
      "Epoch 14340/20000, Train Loss: 0.004741, Val Loss: 0.000064\n",
      "Epoch 14360/20000, Train Loss: 0.004582, Val Loss: 0.000090\n",
      "Epoch 14380/20000, Train Loss: 0.004533, Val Loss: 0.000116\n",
      "Epoch 14400/20000, Train Loss: 0.004726, Val Loss: 0.000037\n",
      "Epoch 14420/20000, Train Loss: 0.004727, Val Loss: 0.000033\n",
      "Epoch 14440/20000, Train Loss: 0.004686, Val Loss: 0.000047\n",
      "Epoch 14460/20000, Train Loss: 0.004565, Val Loss: 0.000067\n",
      "Epoch 14480/20000, Train Loss: 0.004620, Val Loss: 0.000107\n",
      "Epoch 14500/20000, Train Loss: 0.004628, Val Loss: 0.000170\n",
      "Epoch 14520/20000, Train Loss: 0.004629, Val Loss: 0.000084\n",
      "Epoch 14540/20000, Train Loss: 0.004540, Val Loss: 0.000084\n",
      "Epoch 14560/20000, Train Loss: 0.004493, Val Loss: 0.000081\n",
      "Epoch 14580/20000, Train Loss: 0.004594, Val Loss: 0.000084\n",
      "Epoch 14600/20000, Train Loss: 0.004734, Val Loss: 0.000041\n",
      "Epoch 14620/20000, Train Loss: 0.004584, Val Loss: 0.000099\n",
      "Epoch 14640/20000, Train Loss: 0.004656, Val Loss: 0.000105\n",
      "Epoch 14660/20000, Train Loss: 0.004572, Val Loss: 0.000083\n",
      "Epoch 14680/20000, Train Loss: 0.004502, Val Loss: 0.000084\n",
      "Epoch 14700/20000, Train Loss: 0.004575, Val Loss: 0.000075\n",
      "Epoch 14720/20000, Train Loss: 0.004580, Val Loss: 0.000061\n",
      "Epoch 14740/20000, Train Loss: 0.004616, Val Loss: 0.000115\n",
      "Epoch 14760/20000, Train Loss: 0.004613, Val Loss: 0.000099\n",
      "Epoch 14780/20000, Train Loss: 0.004626, Val Loss: 0.000093\n",
      "Epoch 14800/20000, Train Loss: 0.004605, Val Loss: 0.000153\n",
      "Epoch 14820/20000, Train Loss: 0.004542, Val Loss: 0.000048\n",
      "Epoch 14840/20000, Train Loss: 0.004752, Val Loss: 0.000087\n",
      "Epoch 14860/20000, Train Loss: 0.004613, Val Loss: 0.000114\n",
      "Epoch 14880/20000, Train Loss: 0.004581, Val Loss: 0.000066\n",
      "Epoch 14900/20000, Train Loss: 0.004627, Val Loss: 0.000066\n",
      "Epoch 14920/20000, Train Loss: 0.004570, Val Loss: 0.000124\n",
      "Epoch 14940/20000, Train Loss: 0.004566, Val Loss: 0.000132\n",
      "Epoch 14960/20000, Train Loss: 0.004703, Val Loss: 0.000058\n",
      "Epoch 14980/20000, Train Loss: 0.004685, Val Loss: 0.000086\n",
      "Epoch 15000/20000, Train Loss: 0.004578, Val Loss: 0.000072\n",
      "Epoch 15020/20000, Train Loss: 0.004645, Val Loss: 0.000110\n",
      "Epoch 15040/20000, Train Loss: 0.004566, Val Loss: 0.000079\n",
      "Epoch 15060/20000, Train Loss: 0.004570, Val Loss: 0.000053\n",
      "Epoch 15080/20000, Train Loss: 0.004524, Val Loss: 0.000098\n",
      "Epoch 15100/20000, Train Loss: 0.004637, Val Loss: 0.000147\n",
      "Epoch 15120/20000, Train Loss: 0.004603, Val Loss: 0.000069\n",
      "Epoch 15140/20000, Train Loss: 0.004602, Val Loss: 0.000093\n",
      "Epoch 15160/20000, Train Loss: 0.004583, Val Loss: 0.000079\n",
      "Epoch 15180/20000, Train Loss: 0.004610, Val Loss: 0.000141\n",
      "Epoch 15200/20000, Train Loss: 0.004530, Val Loss: 0.000116\n",
      "Epoch 15220/20000, Train Loss: 0.004697, Val Loss: 0.000179\n",
      "Epoch 15240/20000, Train Loss: 0.004614, Val Loss: 0.000084\n",
      "Epoch 15260/20000, Train Loss: 0.004633, Val Loss: 0.000091\n",
      "Epoch 15280/20000, Train Loss: 0.004688, Val Loss: 0.000100\n",
      "Epoch 15300/20000, Train Loss: 0.004569, Val Loss: 0.000103\n",
      "Epoch 15320/20000, Train Loss: 0.004755, Val Loss: 0.000205\n",
      "Epoch 15340/20000, Train Loss: 0.004556, Val Loss: 0.000140\n",
      "Epoch 15360/20000, Train Loss: 0.004566, Val Loss: 0.000194\n",
      "Epoch 15380/20000, Train Loss: 0.004641, Val Loss: 0.000074\n",
      "Epoch 15400/20000, Train Loss: 0.004702, Val Loss: 0.000085\n",
      "Epoch 15420/20000, Train Loss: 0.004700, Val Loss: 0.000118\n",
      "Epoch 15440/20000, Train Loss: 0.004708, Val Loss: 0.000069\n",
      "Epoch 15460/20000, Train Loss: 0.004677, Val Loss: 0.000089\n",
      "Epoch 15480/20000, Train Loss: 0.004680, Val Loss: 0.000084\n",
      "Epoch 15500/20000, Train Loss: 0.004604, Val Loss: 0.000053\n",
      "Epoch 15520/20000, Train Loss: 0.004489, Val Loss: 0.000048\n",
      "Epoch 15540/20000, Train Loss: 0.004665, Val Loss: 0.000078\n",
      "Epoch 15560/20000, Train Loss: 0.004572, Val Loss: 0.000076\n",
      "Epoch 15580/20000, Train Loss: 0.004617, Val Loss: 0.000072\n",
      "Epoch 15600/20000, Train Loss: 0.004608, Val Loss: 0.000074\n",
      "Epoch 15620/20000, Train Loss: 0.004611, Val Loss: 0.000063\n",
      "Epoch 15640/20000, Train Loss: 0.004666, Val Loss: 0.000090\n",
      "Epoch 15660/20000, Train Loss: 0.004708, Val Loss: 0.000062\n",
      "Epoch 15680/20000, Train Loss: 0.004749, Val Loss: 0.000079\n",
      "Epoch 15700/20000, Train Loss: 0.004538, Val Loss: 0.000126\n",
      "Epoch 15720/20000, Train Loss: 0.004590, Val Loss: 0.000044\n",
      "Epoch 15740/20000, Train Loss: 0.004475, Val Loss: 0.000031\n",
      "Epoch 15760/20000, Train Loss: 0.004675, Val Loss: 0.000053\n",
      "Epoch 15780/20000, Train Loss: 0.004572, Val Loss: 0.000104\n",
      "Epoch 15800/20000, Train Loss: 0.004699, Val Loss: 0.000080\n",
      "Epoch 15820/20000, Train Loss: 0.004661, Val Loss: 0.000091\n",
      "Epoch 15840/20000, Train Loss: 0.004673, Val Loss: 0.000058\n",
      "Epoch 15860/20000, Train Loss: 0.004739, Val Loss: 0.000088\n",
      "Epoch 15880/20000, Train Loss: 0.004686, Val Loss: 0.000066\n",
      "Epoch 15900/20000, Train Loss: 0.004620, Val Loss: 0.000071\n",
      "Epoch 15920/20000, Train Loss: 0.004614, Val Loss: 0.000086\n",
      "Epoch 15940/20000, Train Loss: 0.004614, Val Loss: 0.000063\n",
      "Epoch 15960/20000, Train Loss: 0.004538, Val Loss: 0.000059\n",
      "Epoch 15980/20000, Train Loss: 0.004563, Val Loss: 0.000086\n",
      "Epoch 16000/20000, Train Loss: 0.004619, Val Loss: 0.000144\n",
      "Epoch 16020/20000, Train Loss: 0.004654, Val Loss: 0.000126\n",
      "Epoch 16040/20000, Train Loss: 0.004682, Val Loss: 0.000154\n",
      "Epoch 16060/20000, Train Loss: 0.004683, Val Loss: 0.000191\n",
      "Epoch 16080/20000, Train Loss: 0.004597, Val Loss: 0.000112\n",
      "Epoch 16100/20000, Train Loss: 0.004701, Val Loss: 0.000078\n",
      "Epoch 16120/20000, Train Loss: 0.004446, Val Loss: 0.000152\n",
      "Epoch 16140/20000, Train Loss: 0.004534, Val Loss: 0.000115\n",
      "Epoch 16160/20000, Train Loss: 0.004534, Val Loss: 0.000065\n",
      "Epoch 16180/20000, Train Loss: 0.004581, Val Loss: 0.000111\n",
      "Epoch 16200/20000, Train Loss: 0.004536, Val Loss: 0.000107\n",
      "Epoch 16220/20000, Train Loss: 0.004568, Val Loss: 0.000092\n",
      "Epoch 16240/20000, Train Loss: 0.004675, Val Loss: 0.000095\n",
      "Epoch 16260/20000, Train Loss: 0.004530, Val Loss: 0.000088\n",
      "Epoch 16280/20000, Train Loss: 0.004646, Val Loss: 0.000055\n",
      "Epoch 16300/20000, Train Loss: 0.004636, Val Loss: 0.000084\n",
      "Epoch 16320/20000, Train Loss: 0.004662, Val Loss: 0.000119\n",
      "Epoch 16340/20000, Train Loss: 0.004679, Val Loss: 0.000062\n",
      "Epoch 16360/20000, Train Loss: 0.004551, Val Loss: 0.000063\n",
      "Epoch 16380/20000, Train Loss: 0.004663, Val Loss: 0.000049\n",
      "Epoch 16400/20000, Train Loss: 0.004610, Val Loss: 0.000054\n",
      "Epoch 16420/20000, Train Loss: 0.004621, Val Loss: 0.000059\n",
      "Epoch 16440/20000, Train Loss: 0.004589, Val Loss: 0.000045\n",
      "Epoch 16460/20000, Train Loss: 0.004697, Val Loss: 0.000059\n",
      "Epoch 16480/20000, Train Loss: 0.004644, Val Loss: 0.000034\n",
      "Epoch 16500/20000, Train Loss: 0.004601, Val Loss: 0.000048\n",
      "Epoch 16520/20000, Train Loss: 0.004658, Val Loss: 0.000137\n",
      "Epoch 16540/20000, Train Loss: 0.004519, Val Loss: 0.000089\n",
      "Epoch 16560/20000, Train Loss: 0.004645, Val Loss: 0.000107\n",
      "Epoch 16580/20000, Train Loss: 0.004656, Val Loss: 0.000083\n",
      "Epoch 16600/20000, Train Loss: 0.004627, Val Loss: 0.000076\n",
      "Epoch 16620/20000, Train Loss: 0.004505, Val Loss: 0.000088\n",
      "Epoch 16640/20000, Train Loss: 0.004681, Val Loss: 0.000076\n",
      "Epoch 16660/20000, Train Loss: 0.004589, Val Loss: 0.000223\n",
      "Epoch 16680/20000, Train Loss: 0.004638, Val Loss: 0.000107\n",
      "Epoch 16700/20000, Train Loss: 0.004594, Val Loss: 0.000092\n",
      "Epoch 16720/20000, Train Loss: 0.004608, Val Loss: 0.000128\n",
      "Epoch 16740/20000, Train Loss: 0.004572, Val Loss: 0.000133\n",
      "Epoch 16760/20000, Train Loss: 0.004695, Val Loss: 0.000097\n",
      "Epoch 16780/20000, Train Loss: 0.004510, Val Loss: 0.000025\n",
      "Epoch 16800/20000, Train Loss: 0.004537, Val Loss: 0.000076\n",
      "Epoch 16820/20000, Train Loss: 0.004585, Val Loss: 0.000080\n",
      "Epoch 16840/20000, Train Loss: 0.004605, Val Loss: 0.000030\n",
      "Epoch 16860/20000, Train Loss: 0.004570, Val Loss: 0.000049\n",
      "Epoch 16880/20000, Train Loss: 0.004539, Val Loss: 0.000081\n",
      "Epoch 16900/20000, Train Loss: 0.004647, Val Loss: 0.000060\n",
      "Epoch 16920/20000, Train Loss: 0.004553, Val Loss: 0.000039\n",
      "Epoch 16940/20000, Train Loss: 0.004691, Val Loss: 0.000100\n",
      "Epoch 16960/20000, Train Loss: 0.004636, Val Loss: 0.000129\n",
      "Epoch 16980/20000, Train Loss: 0.004656, Val Loss: 0.000092\n",
      "Epoch 17000/20000, Train Loss: 0.004584, Val Loss: 0.000072\n",
      "Epoch 17020/20000, Train Loss: 0.004664, Val Loss: 0.000054\n",
      "Epoch 17040/20000, Train Loss: 0.004607, Val Loss: 0.000061\n",
      "Epoch 17060/20000, Train Loss: 0.004753, Val Loss: 0.000118\n",
      "Epoch 17080/20000, Train Loss: 0.004676, Val Loss: 0.000069\n",
      "Epoch 17100/20000, Train Loss: 0.004556, Val Loss: 0.000073\n",
      "Epoch 17120/20000, Train Loss: 0.004699, Val Loss: 0.000046\n",
      "Epoch 17140/20000, Train Loss: 0.004655, Val Loss: 0.000080\n",
      "Epoch 17160/20000, Train Loss: 0.004615, Val Loss: 0.000089\n",
      "Epoch 17180/20000, Train Loss: 0.004670, Val Loss: 0.000063\n",
      "Epoch 17200/20000, Train Loss: 0.004517, Val Loss: 0.000086\n",
      "Epoch 17220/20000, Train Loss: 0.004599, Val Loss: 0.000096\n",
      "Epoch 17240/20000, Train Loss: 0.004654, Val Loss: 0.000067\n",
      "Epoch 17260/20000, Train Loss: 0.004640, Val Loss: 0.000053\n",
      "Epoch 17280/20000, Train Loss: 0.004652, Val Loss: 0.000052\n",
      "Epoch 17300/20000, Train Loss: 0.004640, Val Loss: 0.000073\n",
      "Epoch 17320/20000, Train Loss: 0.004547, Val Loss: 0.000045\n",
      "Epoch 17340/20000, Train Loss: 0.004754, Val Loss: 0.000059\n",
      "Epoch 17360/20000, Train Loss: 0.004590, Val Loss: 0.000056\n",
      "Epoch 17380/20000, Train Loss: 0.004646, Val Loss: 0.000091\n",
      "Epoch 17400/20000, Train Loss: 0.004543, Val Loss: 0.000167\n",
      "Epoch 17420/20000, Train Loss: 0.004633, Val Loss: 0.000120\n",
      "Epoch 17440/20000, Train Loss: 0.004683, Val Loss: 0.000069\n",
      "Epoch 17460/20000, Train Loss: 0.004613, Val Loss: 0.000056\n",
      "Epoch 17480/20000, Train Loss: 0.004537, Val Loss: 0.000128\n",
      "Epoch 17500/20000, Train Loss: 0.004612, Val Loss: 0.000108\n",
      "Epoch 17520/20000, Train Loss: 0.004691, Val Loss: 0.000085\n",
      "Epoch 17540/20000, Train Loss: 0.004756, Val Loss: 0.000156\n",
      "Epoch 17560/20000, Train Loss: 0.004609, Val Loss: 0.000114\n",
      "Epoch 17580/20000, Train Loss: 0.004842, Val Loss: 0.000092\n",
      "Epoch 17600/20000, Train Loss: 0.004692, Val Loss: 0.000059\n",
      "Epoch 17620/20000, Train Loss: 0.004649, Val Loss: 0.000073\n",
      "Epoch 17640/20000, Train Loss: 0.004448, Val Loss: 0.000102\n",
      "Epoch 17660/20000, Train Loss: 0.004586, Val Loss: 0.000099\n",
      "Epoch 17680/20000, Train Loss: 0.004632, Val Loss: 0.000051\n",
      "Epoch 17700/20000, Train Loss: 0.004624, Val Loss: 0.000068\n",
      "Epoch 17720/20000, Train Loss: 0.004730, Val Loss: 0.000037\n",
      "Epoch 17740/20000, Train Loss: 0.004498, Val Loss: 0.000094\n",
      "Epoch 17760/20000, Train Loss: 0.004595, Val Loss: 0.000067\n",
      "Epoch 17780/20000, Train Loss: 0.004459, Val Loss: 0.000047\n",
      "Epoch 17800/20000, Train Loss: 0.004634, Val Loss: 0.000111\n",
      "Epoch 17820/20000, Train Loss: 0.004729, Val Loss: 0.000085\n",
      "Epoch 17840/20000, Train Loss: 0.004622, Val Loss: 0.000070\n",
      "Epoch 17860/20000, Train Loss: 0.004737, Val Loss: 0.000138\n",
      "Epoch 17880/20000, Train Loss: 0.004611, Val Loss: 0.000118\n",
      "Epoch 17900/20000, Train Loss: 0.004727, Val Loss: 0.000069\n",
      "Epoch 17920/20000, Train Loss: 0.004715, Val Loss: 0.000061\n",
      "Epoch 17940/20000, Train Loss: 0.004591, Val Loss: 0.000077\n",
      "Epoch 17960/20000, Train Loss: 0.004580, Val Loss: 0.000089\n",
      "Epoch 17980/20000, Train Loss: 0.004708, Val Loss: 0.000086\n",
      "Epoch 18000/20000, Train Loss: 0.004557, Val Loss: 0.000092\n",
      "Epoch 18020/20000, Train Loss: 0.004643, Val Loss: 0.000130\n",
      "Epoch 18040/20000, Train Loss: 0.004589, Val Loss: 0.000091\n",
      "Epoch 18060/20000, Train Loss: 0.004669, Val Loss: 0.000064\n",
      "Epoch 18080/20000, Train Loss: 0.004642, Val Loss: 0.000093\n",
      "Epoch 18100/20000, Train Loss: 0.004677, Val Loss: 0.000081\n",
      "Epoch 18120/20000, Train Loss: 0.004577, Val Loss: 0.000121\n",
      "Epoch 18140/20000, Train Loss: 0.004509, Val Loss: 0.000153\n",
      "Epoch 18160/20000, Train Loss: 0.004657, Val Loss: 0.000096\n",
      "Epoch 18180/20000, Train Loss: 0.004571, Val Loss: 0.000096\n",
      "Epoch 18200/20000, Train Loss: 0.004597, Val Loss: 0.000077\n",
      "Epoch 18220/20000, Train Loss: 0.004666, Val Loss: 0.000129\n",
      "Epoch 18240/20000, Train Loss: 0.004608, Val Loss: 0.000080\n",
      "Epoch 18260/20000, Train Loss: 0.004736, Val Loss: 0.000091\n",
      "Epoch 18280/20000, Train Loss: 0.004580, Val Loss: 0.000183\n",
      "Epoch 18300/20000, Train Loss: 0.004585, Val Loss: 0.000093\n",
      "Epoch 18320/20000, Train Loss: 0.004456, Val Loss: 0.000051\n",
      "Epoch 18340/20000, Train Loss: 0.004640, Val Loss: 0.000073\n",
      "Epoch 18360/20000, Train Loss: 0.004592, Val Loss: 0.000139\n",
      "Epoch 18380/20000, Train Loss: 0.004583, Val Loss: 0.000150\n",
      "Epoch 18400/20000, Train Loss: 0.004454, Val Loss: 0.000161\n",
      "Epoch 18420/20000, Train Loss: 0.004687, Val Loss: 0.000092\n",
      "Epoch 18440/20000, Train Loss: 0.004629, Val Loss: 0.000079\n",
      "Epoch 18460/20000, Train Loss: 0.004701, Val Loss: 0.000096\n",
      "Epoch 18480/20000, Train Loss: 0.004662, Val Loss: 0.000093\n",
      "Epoch 18500/20000, Train Loss: 0.004649, Val Loss: 0.000067\n",
      "Epoch 18520/20000, Train Loss: 0.004480, Val Loss: 0.000035\n",
      "Epoch 18540/20000, Train Loss: 0.004515, Val Loss: 0.000042\n",
      "Epoch 18560/20000, Train Loss: 0.004673, Val Loss: 0.000048\n",
      "Epoch 18580/20000, Train Loss: 0.004520, Val Loss: 0.000087\n",
      "Epoch 18600/20000, Train Loss: 0.004573, Val Loss: 0.000141\n",
      "Epoch 18620/20000, Train Loss: 0.004613, Val Loss: 0.000091\n",
      "Epoch 18640/20000, Train Loss: 0.004750, Val Loss: 0.000105\n",
      "Epoch 18660/20000, Train Loss: 0.004554, Val Loss: 0.000077\n",
      "Epoch 18680/20000, Train Loss: 0.004619, Val Loss: 0.000135\n",
      "Epoch 18700/20000, Train Loss: 0.004584, Val Loss: 0.000120\n",
      "Epoch 18720/20000, Train Loss: 0.004627, Val Loss: 0.000179\n",
      "Epoch 18740/20000, Train Loss: 0.004717, Val Loss: 0.000102\n",
      "Epoch 18760/20000, Train Loss: 0.004649, Val Loss: 0.000079\n",
      "Epoch 18780/20000, Train Loss: 0.004694, Val Loss: 0.000066\n",
      "Epoch 18800/20000, Train Loss: 0.004647, Val Loss: 0.000127\n",
      "Epoch 18820/20000, Train Loss: 0.004756, Val Loss: 0.000086\n",
      "Epoch 18840/20000, Train Loss: 0.004644, Val Loss: 0.000064\n",
      "Epoch 18860/20000, Train Loss: 0.004583, Val Loss: 0.000184\n",
      "Epoch 18880/20000, Train Loss: 0.004631, Val Loss: 0.000159\n",
      "Epoch 18900/20000, Train Loss: 0.004612, Val Loss: 0.000125\n",
      "Epoch 18920/20000, Train Loss: 0.004682, Val Loss: 0.000175\n",
      "Epoch 18940/20000, Train Loss: 0.004596, Val Loss: 0.000152\n",
      "Epoch 18960/20000, Train Loss: 0.004502, Val Loss: 0.000075\n",
      "Epoch 18980/20000, Train Loss: 0.004671, Val Loss: 0.000062\n",
      "Epoch 19000/20000, Train Loss: 0.004468, Val Loss: 0.000115\n",
      "Epoch 19020/20000, Train Loss: 0.004616, Val Loss: 0.000065\n",
      "Epoch 19040/20000, Train Loss: 0.004643, Val Loss: 0.000083\n",
      "Epoch 19060/20000, Train Loss: 0.004549, Val Loss: 0.000217\n",
      "Epoch 19080/20000, Train Loss: 0.004588, Val Loss: 0.000085\n",
      "Epoch 19100/20000, Train Loss: 0.004674, Val Loss: 0.000050\n",
      "Epoch 19120/20000, Train Loss: 0.004582, Val Loss: 0.000080\n",
      "Epoch 19140/20000, Train Loss: 0.004567, Val Loss: 0.000140\n",
      "Epoch 19160/20000, Train Loss: 0.004750, Val Loss: 0.000081\n",
      "Epoch 19180/20000, Train Loss: 0.004733, Val Loss: 0.000163\n",
      "Epoch 19200/20000, Train Loss: 0.004586, Val Loss: 0.000049\n",
      "Epoch 19220/20000, Train Loss: 0.004585, Val Loss: 0.000071\n",
      "Epoch 19240/20000, Train Loss: 0.004666, Val Loss: 0.000100\n",
      "Epoch 19260/20000, Train Loss: 0.004503, Val Loss: 0.000062\n",
      "Epoch 19280/20000, Train Loss: 0.004609, Val Loss: 0.000073\n",
      "Epoch 19300/20000, Train Loss: 0.004616, Val Loss: 0.000067\n",
      "Epoch 19320/20000, Train Loss: 0.004529, Val Loss: 0.000072\n",
      "Epoch 19340/20000, Train Loss: 0.004637, Val Loss: 0.000118\n",
      "Epoch 19360/20000, Train Loss: 0.004738, Val Loss: 0.000081\n",
      "Epoch 19380/20000, Train Loss: 0.004570, Val Loss: 0.000103\n",
      "Epoch 19400/20000, Train Loss: 0.004582, Val Loss: 0.000033\n",
      "Epoch 19420/20000, Train Loss: 0.004598, Val Loss: 0.000070\n",
      "Epoch 19440/20000, Train Loss: 0.004595, Val Loss: 0.000053\n",
      "Epoch 19460/20000, Train Loss: 0.004541, Val Loss: 0.000110\n",
      "Epoch 19480/20000, Train Loss: 0.004569, Val Loss: 0.000167\n",
      "Epoch 19500/20000, Train Loss: 0.004592, Val Loss: 0.000055\n",
      "Epoch 19520/20000, Train Loss: 0.004559, Val Loss: 0.000075\n",
      "Epoch 19540/20000, Train Loss: 0.004549, Val Loss: 0.000059\n",
      "Epoch 19560/20000, Train Loss: 0.004678, Val Loss: 0.000117\n",
      "Epoch 19580/20000, Train Loss: 0.004583, Val Loss: 0.000132\n",
      "Epoch 19600/20000, Train Loss: 0.004598, Val Loss: 0.000150\n",
      "Epoch 19620/20000, Train Loss: 0.004662, Val Loss: 0.000180\n",
      "Epoch 19640/20000, Train Loss: 0.004579, Val Loss: 0.000059\n",
      "Epoch 19660/20000, Train Loss: 0.004618, Val Loss: 0.000097\n",
      "Epoch 19680/20000, Train Loss: 0.004598, Val Loss: 0.000089\n",
      "Epoch 19700/20000, Train Loss: 0.004626, Val Loss: 0.000118\n",
      "Epoch 19720/20000, Train Loss: 0.004661, Val Loss: 0.000074\n",
      "Epoch 19740/20000, Train Loss: 0.004531, Val Loss: 0.000153\n",
      "Epoch 19760/20000, Train Loss: 0.004564, Val Loss: 0.000152\n",
      "Epoch 19780/20000, Train Loss: 0.004537, Val Loss: 0.000108\n",
      "Epoch 19800/20000, Train Loss: 0.004509, Val Loss: 0.000052\n",
      "Epoch 19820/20000, Train Loss: 0.004573, Val Loss: 0.000065\n",
      "Epoch 19840/20000, Train Loss: 0.004526, Val Loss: 0.000089\n",
      "Epoch 19860/20000, Train Loss: 0.004702, Val Loss: 0.000062\n",
      "Epoch 19880/20000, Train Loss: 0.004684, Val Loss: 0.000056\n",
      "Epoch 19900/20000, Train Loss: 0.004518, Val Loss: 0.000142\n",
      "Epoch 19920/20000, Train Loss: 0.004557, Val Loss: 0.000053\n",
      "Epoch 19940/20000, Train Loss: 0.004633, Val Loss: 0.000114\n",
      "Epoch 19960/20000, Train Loss: 0.004523, Val Loss: 0.000113\n",
      "Epoch 19980/20000, Train Loss: 0.004623, Val Loss: 0.000174\n",
      "Epoch 20000/20000, Train Loss: 0.004673, Val Loss: 0.000073\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 1000x600 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.model_selection import train_test_split\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# =========================\n",
    "# 1️⃣ Prepare dataset\n",
    "# =========================\n",
    "soil_cols = [\n",
    "    'ph','organic_matter','total_nitrogen','potassium','p2o5','boron','zinc',\n",
    "    'sand','clay','slit','parentsoil','crop','variety', 't2m_C','tp_mm'\n",
    "]\n",
    "fert_cols = ['UREA1','UREA2','UREA3','DAP','MOP']\n",
    "\n",
    "# Load df as your dataset\n",
    "df = df.dropna(subset=soil_cols + fert_cols)\n",
    "df = df.sample(min(25000, len(df)), random_state=42).reset_index(drop=True)\n",
    "\n",
    "# Train-test split BEFORE scaling\n",
    "X = df[soil_cols]\n",
    "y = df[fert_cols]\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    X, y, test_size=0.2, random_state=42\n",
    ")\n",
    "\n",
    "# =========================\n",
    "# 2️⃣ Feature & target scaling (train only)\n",
    "# =========================\n",
    "scaler_X = StandardScaler()\n",
    "X_train_scaled = scaler_X.fit_transform(X_train)\n",
    "X_test_scaled = scaler_X.transform(X_test)\n",
    "\n",
    "scaler_y = StandardScaler()\n",
    "y_train_scaled = scaler_y.fit_transform(y_train)\n",
    "y_test_scaled = scaler_y.transform(y_test)\n",
    "\n",
    "# Convert to tensors\n",
    "X_train_tensor = torch.tensor(X_train_scaled, dtype=torch.float32)\n",
    "y_train_tensor = torch.tensor(y_train_scaled, dtype=torch.float32)\n",
    "X_test_tensor = torch.tensor(X_test_scaled, dtype=torch.float32)\n",
    "y_test_tensor = torch.tensor(y_test_scaled, dtype=torch.float32)\n",
    "\n",
    "# Precompute min/max for clipping\n",
    "fert_min = np.zeros(len(fert_cols))           # no negative fertilizers\n",
    "fert_max = y_train.max().values               # realistic max per fertilizer\n",
    "\n",
    "# =========================\n",
    "# 3️⃣ Define model with Dropout\n",
    "# =========================\n",
    "class FertNetDropout(nn.Module):\n",
    "    def __init__(self, input_dim, output_dim, dropout=0.2):\n",
    "        super().__init__()\n",
    "        self.net = nn.Sequential(\n",
    "            nn.Linear(input_dim, 256), nn.ReLU(),\n",
    "            nn.Dropout(dropout),\n",
    "            nn.Linear(256, 256), nn.ReLU(),\n",
    "            nn.Dropout(dropout),\n",
    "            nn.Linear(256, output_dim)\n",
    "        )\n",
    "    def forward(self, x):\n",
    "        return self.net(x)\n",
    "\n",
    "model = FertNetDropout(X_train_tensor.shape[1], y_train_tensor.shape[1])\n",
    "criterion = nn.MSELoss()\n",
    "optimizer = optim.Adam(model.parameters(), lr=1e-3)\n",
    "\n",
    "# =========================\n",
    "# 4️⃣ Train the model\n",
    "# =========================\n",
    "epochs = 20000\n",
    "train_loss_list = []\n",
    "val_loss_list = []\n",
    "\n",
    "for ep in range(1, epochs+1):\n",
    "    model.train()\n",
    "    optimizer.zero_grad()\n",
    "    outputs = model(X_train_tensor)\n",
    "    loss = criterion(outputs, y_train_tensor)\n",
    "    loss.backward()\n",
    "    optimizer.step()\n",
    "    train_loss_list.append(loss.item())\n",
    "\n",
    "    # Validation loss\n",
    "    model.eval()\n",
    "    with torch.no_grad():\n",
    "        val_outputs = model(X_test_tensor)\n",
    "        val_loss = criterion(val_outputs, y_test_tensor)\n",
    "        val_loss_list.append(val_loss.item())\n",
    "\n",
    "    if ep % 20 == 0 or ep == 1:\n",
    "        print(f\"Epoch {ep}/{epochs}, Train Loss: {loss.item():.6f}, Val Loss: {val_loss.item():.6f}\")\n",
    "\n",
    "# Save the trained model\n",
    "torch.save(model.state_dict(), \"fertilizer_model_dropout_clean.pth\")\n",
    "\n",
    "# =========================\n",
    "# 5️⃣ Plot Loss\n",
    "# =========================\n",
    "plt.figure(figsize=(10,6))\n",
    "plt.plot(train_loss_list, label='Train Loss')\n",
    "plt.plot(val_loss_list, label='Validation Loss')\n",
    "plt.xlabel(\"Epoch\")\n",
    "plt.ylabel(\"MSE Loss\")\n",
    "plt.title(\"Train vs Validation Loss\")\n",
    "plt.legend()\n",
    "plt.show()\n",
    "\n",
    "# =========================\n",
    "# 6️⃣ Prediction with % uncertainty\n",
    "# =========================\n",
    "def predict_fertilizer_with_percent_uncertainty(input_features, mc_runs=50):\n",
    "    \"\"\"\n",
    "    Predict fertilizer amounts with Monte Carlo Dropout uncertainty (as %)\n",
    "    input_features: list or array of soil features in the order of soil_cols\n",
    "    mc_runs: number of forward passes for uncertainty estimation\n",
    "    Returns: mean prediction and percentage uncertainty for each fertilizer\n",
    "    \"\"\"\n",
    "    x_df = pd.DataFrame([input_features], columns=soil_cols)\n",
    "    x_scaled = scaler_X.transform(x_df)\n",
    "    x_tensor = torch.tensor(x_scaled, dtype=torch.float32)\n",
    "\n",
    "    # Enable dropout during inference\n",
    "    model.train()\n",
    "    preds = []\n",
    "\n",
    "    for _ in range(mc_runs):\n",
    "        with torch.no_grad():\n",
    "            y_scaled_pred = model(x_tensor).numpy()\n",
    "        y_pred = scaler_y.inverse_transform(y_scaled_pred)\n",
    "        y_pred_clipped = np.clip(y_pred, fert_min, fert_max)\n",
    "        preds.append(y_pred_clipped.flatten())\n",
    "\n",
    "    preds = np.array(preds)\n",
    "    pred_mean = preds.mean(axis=0)\n",
    "    pred_std = preds.std(axis=0)\n",
    "    \n",
    "    # Convert std to percentage of predicted amount\n",
    "    pred_percent_uncertainty = (pred_std / pred_mean) * 100\n",
    "    return pred_mean, pred_percent_uncertainty\n",
    "\n",
    "# =========================\n",
    "# 7️⃣ Example usage on unseen data\n",
    "# =========================\n",
    "# Suppose unseen_df is another DataFrame of completely new data\n",
    "# unseen_df = pd.read_csv(\"unseen_data.csv\")\n",
    "# sample_input = unseen_df.iloc[0][soil_cols].values\n",
    "# pred_mean, pred_percent = predict_fertilizer_with_percent_uncertainty(sample_input, mc_runs=50)\n",
    "\n",
    "# for f, m, p in zip(fert_cols, pred_mean, pred_percent):\n",
    "#     print(f\"{f}: {m:.2f} units ± {p:.1f}%\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "4b32f2d1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['../../models/fert_optimization/scaler_y_rl_ppo.pkl']"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import joblib\n",
    "\n",
    "# Save feature scaler\n",
    "joblib.dump(scaler_X, \"../../models/fert_optimization/scaler_X_rlppo.pkl\")\n",
    "\n",
    "# Save target scaler\n",
    "joblib.dump(scaler_y, \"../../models/fert_optimization/scaler_y_rl_ppo.pkl\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9e5e70f0",
   "metadata": {},
   "source": [
    "import joblib\n",
    "\n",
    "# Save feature scaler\n",
    "joblib.dump(scaler_X, \"scaler_X.pkl\")\n",
    "\n",
    "# Save target scaler\n",
    "joblib.dump(scaler_y, \"scaler_y.pkl\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ce164281",
   "metadata": {},
   "outputs": [],
   "source": [
    "# "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "nlp-env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
